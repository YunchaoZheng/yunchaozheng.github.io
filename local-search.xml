<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>五十音図</title>
    <link href="/2022/07/20/%E4%BA%94%E5%8D%81%E9%9F%B3%E5%9B%B3/"/>
    <url>/2022/07/20/%E4%BA%94%E5%8D%81%E9%9F%B3%E5%9B%B3/</url>
    
    <content type="html"><![CDATA[<p>五十音図，因为老是记不住五十音所以特地列一下，还不是因为说的少用的少导致的</p><h3 id="五十音図"><a href="#五十音図" class="headerlink" title="五十音図"></a>五十音図</h3><table><thead><tr><th><strong>五十音</strong></th><th>あ段</th><th>い段</th><th>う段</th><th>え段</th><th>お段</th></tr></thead><tbody><tr><td><strong>あ行</strong></td><td>あ、ア</td><td>い、イ</td><td>う、ウ</td><td>え、エ</td><td>お、オ</td></tr><tr><td><strong>か行</strong></td><td>か、カ</td><td>き、キ</td><td>く、ク</td><td>け、ケ</td><td>こ、コ</td></tr><tr><td><strong>さ行</strong></td><td>さ、サ</td><td>し、シ</td><td>す、ス</td><td>せ、セ</td><td>そ、ソ</td></tr><tr><td><strong>た行</strong></td><td>た、タ</td><td>ち、チ</td><td>つ、ツ</td><td>て、テ</td><td>と、ト</td></tr><tr><td><strong>な行</strong></td><td>な、ナ</td><td>に、ニ</td><td>ぬ、ヌ</td><td>ね、ネ</td><td>の、ノ</td></tr><tr><td><strong>は行</strong></td><td>は、ハ</td><td>ひ、ヒ</td><td>ふ、フ</td><td>へ、ヘ</td><td>ほ、ホ</td></tr><tr><td><strong>ま行</strong></td><td>ま、マ</td><td>み、ミ</td><td>む、ム</td><td>め、メ</td><td>も、モ</td></tr><tr><td><strong>や行</strong></td><td>や、ヤ</td><td>い、イ</td><td>ゆ、ユ</td><td>え、エ</td><td>よ、ヨ</td></tr><tr><td><strong>ら行</strong></td><td>ら、ラ</td><td>り、リ</td><td>る、ル</td><td>れ、レ</td><td>ろ、ロ</td></tr><tr><td><strong>わ行</strong></td><td>わ、ワ</td><td>い、イ</td><td>う、ウ</td><td>え、エ</td><td>を、ヲ</td></tr><tr><td></td><td></td><td>ん、ン</td><td></td><td></td><td></td></tr></tbody></table><h3 id="补充音図１"><a href="#补充音図１" class="headerlink" title="补充音図１"></a>补充音図１</h3><table><thead><tr><th><strong>补充1</strong></th><th>や段</th><th>ゆ段</th><th>よ段</th></tr></thead><tbody><tr><td><strong>か行</strong></td><td>きゃ、キャ</td><td>きゅ、キュ</td><td>きょ、キョ</td></tr><tr><td><strong>さ行</strong></td><td>しゃ、シャ</td><td>しゅ、シュ</td><td>しょ、ショ</td></tr><tr><td><strong>た行</strong></td><td>ちゃ、チャ</td><td>ちゅ、チュ</td><td>ちょ、チョ</td></tr><tr><td><strong>な行</strong></td><td>にゃ、ニャ</td><td>にゅ、ニュ</td><td>にょ、ニョ</td></tr><tr><td><strong>は行</strong></td><td>ひゃ、ヒャ</td><td>ひゅ、ヒュ</td><td>ひょ、ヒョ</td></tr><tr><td><strong>ま行</strong></td><td>みゃ、ミャ</td><td>みゅ、ミュ</td><td>みょ、ミョ</td></tr><tr><td><strong>ら行</strong></td><td>りゃ、リャ</td><td>りゅ、リュ</td><td>りょ、リョ</td></tr><tr><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td><strong>が行</strong></td><td>ぎゃ、ギャ</td><td>ぎゅ、ギュ</td><td>ぎょ、ギョ</td></tr><tr><td><strong>ざ行</strong></td><td>じゃ、ジャ</td><td>じゅ、ジュ</td><td>じょ、ジョ</td></tr><tr><td><strong>ば行</strong></td><td>びゃ、ビャ</td><td>びゅ、ビュ</td><td>びょ、ビョ</td></tr><tr><td><strong>ぱ行</strong></td><td>ぴゃ、ピャ</td><td>ぴゅ、ピュ</td><td>ぴょ、ピョ</td></tr></tbody></table><h3 id="补充音図２"><a href="#补充音図２" class="headerlink" title="补充音図２"></a>补充音図２</h3><table><thead><tr><th><strong>补充2</strong></th><th>あ段</th><th>い段</th><th>う段</th><th>え段</th><th>お段</th></tr></thead><tbody><tr><td><strong>が行</strong></td><td>が、ガ</td><td>ぎ、ギ</td><td>ぐ、グ</td><td>げ、ゲ</td><td>ご、ゴ</td></tr><tr><td><strong>ざ行</strong></td><td>ざ、ザ</td><td>じ、ジ</td><td>ず、ズ</td><td>ぜ、ゼ</td><td>ぞ、ゾ</td></tr><tr><td><strong>だ行</strong></td><td>だ、ダ</td><td>じ、ジ</td><td>ず、ズ</td><td>で、デ</td><td>ど、ド</td></tr><tr><td><strong>ば行</strong></td><td>ば、バ</td><td>び、ビ</td><td>ぶ、ブ</td><td>べ、ベ</td><td>ぼ、ボ</td></tr><tr><td><strong>ぱ行</strong></td><td>ぱ、パ</td><td>ぴ、ピ</td><td>ぷ、プ</td><td>ぺ、ペ</td><td>ぽ、ポ</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>Thoughts</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Intra-Correlation Encoding for Chinese Sentence Intention Matching</title>
    <link href="/2022/05/09/wannot-readpaper-0004/"/>
    <url>/2022/05/09/wannot-readpaper-0004/</url>
    
    <content type="html"><![CDATA[<h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><p>作者: Xu Zhang, Yifeng Li, Wenpeng Lu, Ping Jian, Guoqiang Zhang<br>主要机构: School of Computer Science and Technology、Qilu University of Technology (Shandong Academy of Sciences)<br>来源: COLING 2020<br>提交时间: 2020<br>关键词: sentence intention matching</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>文本嵌入</category>
      
    </categories>
    
    
    <tags>
      
      <tag>语义相似</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AML-2 Free Talk</title>
    <link href="/2022/04/25/AML-2-free-talk/"/>
    <url>/2022/04/25/AML-2-free-talk/</url>
    
    <content type="html"><![CDATA[<p><strong>Q:</strong><br><strong>What is overfitting in machine learning?</strong><br><strong>What are the reasons of causing overfitting?</strong><br><strong>How to reduce overfitting?</strong></p><p>A:<br>Overfitting means that the model performs well on the train data, but too well that the model generalize very poorly.<br>The model just learned too well with the hidden unlinear capbility on train data</p><p>Reasons, many. </p><ul><li>Too few train data</li><li>Noisy/dirty train data</li><li>Too many iterations</li><li>Wrongly divided train/test sets. Exp, train with some patterns while test without.</li></ul><p>Techs to reduce overfitting</p><ul><li>data augmentation. exp, resampling.</li><li>make a simpler model. sometimes linear model performs well too.</li><li>regularization, to punish the complex model</li><li>dropout</li><li>early stop</li></ul><hr><p><strong>Q:</strong><br><strong>What are the main roles of pooling?</strong><br><strong>What problems can be solved by pooling?</strong><br><strong>What’s the differences between max-pooling and average-pooling?</strong></p><p>A:<br>pooling, to subsample the input image(by convolutional layers) to reduce the dimention, compute &amp; memory load or parameters.</p><p>As mentioned, pooling can reduce dimention, compute load or parameters.<br>The convolutional layers only reduce the size of image tiny a bit. Thus, pooling tech with proper size &amp; stride to reduce the memory requirement is vital.<br>Also, pooling layers alse introduce some level of invariance of small changes, such as move, rotation, etc.</p><p>max-pooling computes the max of the kernel, while average-pooling computes the mean of the kernel.<br>max-pooling selects the strongest features, ignores the weak ones, also requires slightly less compute than average-pooling<br>max-pooling loses the weak features, while average-pooling loses both strong and weak features, more engineers perfer max-pooling.</p><hr><p><strong>Q:</strong><br><strong>Please compare the differences between attention and self-attention.</strong></p><p>A:<br>Not quite understand attention mechanism, thus answer in brief<br>Found at some blogs. Attention can be represented a map from a Query to a Pair of key-value.<br>Attention is a average-sum of softmax(Queryi-Keyi), which is the map of Q to KV, tells you that which K-V is most important to Q</p><p>Self-Att is some kind like adjance matrix, represents the connection of K-Vs. Not quite understand this but read many papers used it.</p><p>Conclusion, Attention is the importance measure of K-Vs from a Query.<br>Self Attention is the importance measure of a K-V to other K-Vs.</p>]]></content>
    
    
    
    <tags>
      
      <tag>Thoughts</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>「最优化方法」MOOC Chapter 2.3.4 Solution</title>
    <link href="/2022/04/05/optimization-methods-mooc-homework/"/>
    <url>/2022/04/05/optimization-methods-mooc-homework/</url>
    
    <content type="html"><![CDATA[<p>注：本文有精确的源码 commit 时间戳，请勿抄作业。<br>注2：本文仅供记录和学习，请勿抄作业。</p><h1 id="第-2-章"><a href="#第-2-章" class="headerlink" title="第 2 章"></a>第 2 章</h1><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405145054.png" class="" title="1" alt="1"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/hwid1240793141s-1.jpg" class="" title="1.s" alt="1.s"><h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405145215.png" class="" title="2" alt="2"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/hwid1240793141s-2-1.jpg" class="" title="2.s1" alt="2.s1"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/hwid1240793141s-2-2.jpg" class="" title="2.s2" alt="2.s2"><h2 id="3"><a href="#3" class="headerlink" title="3"></a>3</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405145527.png" class="" title="3" alt="3"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/hwid1240793141s-3.jpg" class="" title="3.s" alt="3.s"><h2 id="4"><a href="#4" class="headerlink" title="4"></a>4</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405145702.png" class="" title="4" alt="4"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/hwid1240793141s-4.jpg" class="" title="4.s" alt="4.s"><h2 id="5"><a href="#5" class="headerlink" title="5"></a>5</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405145813.png" class="" title="5" alt="5"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/hwid1240793141s-5.jpg" class="" title="5.s" alt="5.s"><h1 id="第-3-章"><a href="#第-3-章" class="headerlink" title="第 3 章"></a>第 3 章</h1><h2 id="1-1"><a href="#1-1" class="headerlink" title="1"></a>1</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405150015.png" class="" title="1" alt="1"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0643.PNG" class="" title="1.s" alt="1.s"><h2 id="2-1"><a href="#2-1" class="headerlink" title="2"></a>2</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405150121.png" class="" title="2" alt="2"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/3888181087187cc7705728941abed3f.png" class="" title="2.s" alt="2.s"><h2 id="3-1"><a href="#3-1" class="headerlink" title="3"></a>3</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405150233.png" class="" title="3" alt="3"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/5913660d9faeabc503384c4ecf8a856.png" class="" title="3.s" alt="3.s"><h2 id="4-1"><a href="#4-1" class="headerlink" title="4"></a>4</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405150426.png" class="" title="4" alt="4"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0646.PNG" class="" title="4.s" alt="4.s"><h2 id="5-1"><a href="#5-1" class="headerlink" title="5"></a>5</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405150527.png" class="" title="5" alt="5"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0649.PNG" class="" title="5.s" alt="5.s"><h2 id="6"><a href="#6" class="headerlink" title="6"></a>6</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405150657.png" class="" title="6" alt="6"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/681f783fa715dca04089ac33e353078.png" class="" title="6.s" alt="6.s"><h2 id="7"><a href="#7" class="headerlink" title="7"></a>7</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405150813.png" class="" title="7" alt="7"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0650.PNG" class="" title="7.s" alt="7.s"><h1 id="第-4-章"><a href="#第-4-章" class="headerlink" title="第 4 章"></a>第 4 章</h1><h2 id="1-2"><a href="#1-2" class="headerlink" title="1"></a>1</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405151042.png" class="" title="1" alt="1"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0689.PNG" class="" title="1.s" alt="1.s"><h2 id="2-2"><a href="#2-2" class="headerlink" title="2"></a>2</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405151145.png" class="" title="2" alt="2"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0690.PNG" class="" title="2.s" alt="2.s"><h2 id="3-2"><a href="#3-2" class="headerlink" title="3"></a>3</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405151257.png" class="" title="3" alt="3"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0691.PNG" class="" title="3.s" alt="3.s"><h2 id="4-2"><a href="#4-2" class="headerlink" title="4"></a>4</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405151400.png" class="" title="4" alt="4"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0692.PNG" class="" title="4.s" alt="4.s"><h2 id="5-2"><a href="#5-2" class="headerlink" title="5"></a>5</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405151458.png" class="" title="5" alt="5"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0693.PNG" class="" title="5.s" alt="5.s"><h2 id="6-1"><a href="#6-1" class="headerlink" title="6"></a>6</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220405151602.png" class="" title="6" alt="6"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/IMG_0694.PNG" class="" title="6.s" alt="6.s"><hr><p>当朋友向我问已经做好的题</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/2cda44631a59c87e1c10fd5d6d99798.jpg" class="">]]></content>
    
    
    
    <tags>
      
      <tag>Thoughts</tag>
      
      <tag>优化方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MM-Rec:Multimodal News Recommendation</title>
    <link href="/2022/03/10/wannot-readpaper-0003/"/>
    <url>/2022/03/10/wannot-readpaper-0003/</url>
    
    <content type="html"><![CDATA[<h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><p>作者: Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang等<br>主要机构: Department of Electronic Engineering &amp; BNRist, Tsinghua University、Microsoft Research Asia<br>来源: SIGIR 2021(In Proceeding，貌似应该没发出来)<br>提交时间: 2021-Apr-15<br>关键词: News RS, Multimodality</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这篇文章废话不多，干话，也不多，用艾尔登法环体总结如下：</p><blockquote><p>前无带图片的新闻数据集</p><p>接下来，带图片的新闻数据集很有用</p><p>前无图片嵌入的新闻推荐</p><p>接下来，图片嵌入的新闻推荐很有用</p></blockquote><p>实际上，这篇文章主要贡献两个：一、爬取了 [Feb. 25, 2020 to Mar. 16, 2020] 这段时间的 Microsoft News，并且和 Mind 数据集(微软新闻数据集，加上超链接)一样加了 click 数据，形成了一个带图片的新闻数据集；二、建立了一个文本+图片嵌入的 ctr 预测模型</p><h1 id="Inspiration"><a href="#Inspiration" class="headerlink" title="Inspiration"></a>Inspiration</h1><p>不行不行，不加一点东西开组会老师不能买账啊。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220330154658.png" class="" title="News with images for news recommendation" alt="News with images for news recommendation"><p>新闻标题和图片在吸引用户注意力，进行点击这一行为链中通常具有隐含的关联性。这一点是直观性的，从上图给出的一个 click 看到，用户点击的一组新闻中，第二条新闻的关键词 “cowboy” 与图中的球员相关（但是不能从语义上判断），因此通过图片嵌入的信息，可以从图3挖掘出相似的图片嵌入，进而进行推荐。这一点在传统利用文本挖掘的推荐系统中是缺乏利用的。</p><h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p>先整理一下目前都能收集到的新闻数据集吧，公开与非公开(但能共享)的，一部分新闻数据集不公开的原因是版权的问题，还有一部分可能是作者不想做公开，毕竟流量费用还挺贵的。</p><table><thead><tr><th>DataSet</th><th>Lang</th><th>Users</th><th>News</th><th>Clicks</th><th>News Info</th><th>Link</th></tr></thead><tbody><tr><td>Plisa</td><td>German</td><td>Unknown</td><td>70,353</td><td>1,095,323</td><td>title,body</td><td></td></tr><tr><td>Adressa</td><td>Norwegian</td><td>3,083,438</td><td>48,486</td><td>27,223,576</td><td>title,body,category</td><td></td></tr><tr><td>Globo</td><td>Portuguese</td><td>314,000</td><td>46,000</td><td>3,000,000</td><td>No Origin, only word embeddings</td><td></td></tr><tr><td>Yahoo!</td><td>English</td><td>Unknown</td><td>14,180</td><td>34,022</td><td>No Origin, only word IDs</td><td></td></tr><tr><td>Mind</td><td>English</td><td>1,000,000</td><td>161,013</td><td>24,155,470</td><td>title,body(need crawl),category,link</td><td></td></tr></tbody></table><p>Not OA but shared</p><table><thead><tr><th>DataSet</th><th>Lang</th><th>Users</th><th>News</th><th>Clicks</th><th>News Info</th><th>Link</th></tr></thead><tbody><tr><td>Mind_MM-Rec</td><td>English</td><td>Unknown</td><td>Unknown</td><td>Unknown</td><td>title,body(need crawl),image,category,link</td><td></td></tr><tr><td>Visual News</td><td>English</td><td>Unknown</td><td>Unknown</td><td>Unknown</td><td>title,image</td><td></td></tr><tr><td>Picture News Collection</td><td>Chinese</td><td>Unknown</td><td>Unknown</td><td>Unknown</td><td>title,image</td><td><a href="https://pan.baidu.com/s/1coR2p19l_xCpJTD7n5opIA#list/path=%2F">https://pan.baidu.com/s/1coR2p19l_xCpJTD7n5opIA#list/path=%2F</a></td></tr><tr><td>Corpus of Images and Text</td><td>English</td><td>Unknown</td><td>Unknown</td><td>Unknown</td><td>title,body*,image*,category,link  (* stored as feature vector)</td><td><a href="https://github.com/abedjeti/ADS-NewsArticles">https://github.com/abedjeti/ADS-NewsArticles</a></td></tr></tbody></table><h1 id="MM-NRec"><a href="#MM-NRec" class="headerlink" title="MM-NRec"></a>MM-NRec</h1><p>MM-Rec 全称叫 Multimodality News Recommand System 多模态新闻推荐系统，其实是融合了文本和图片信息进行新闻推荐。<br>它的核心组件有两部分：多模态新闻编码器(Multimodal News Encoder)、多模态新闻推荐(Multimodal News Recommendation)</p><h2 id="多模态新闻编码"><a href="#多模态新闻编码" class="headerlink" title="多模态新闻编码"></a>多模态新闻编码</h2><p>对于有标题、类别、正文、图片等多种内容的新闻来说：</p><ol><li>用户点击新闻不仅是因为他们对新闻标题感兴趣，而且也是因为新闻图片的吸引力，多模态建模很重要</li><li>新闻图像中的不同区域也有不同的信息量</li><li>同一新闻的标题和图片通常有一些相互之间的关系</li></ol><p>MM-NRec 首先用多模态新闻编码器(下面简称MNE)对新闻内容进行编码，但是 MM-NRec 的作者只使用了【图片+标题】这两种信息，明明是和 Mind 数据集作者合作的怎么不用全文…对图片进行了注意力检测，对标题进行序列化然后放到一大张 ViLBERT 进行嵌入。</p><p>首先来看一下多模态新闻编码器，这里是原文画的图：</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220331164032.png" class="" title="多模态新闻编码器结构图" alt="多模态新闻编码器结构图"><h3 id="ROI"><a href="#ROI" class="headerlink" title="ROI"></a>ROI</h3><p>Region of Interest，RoI是指 Selective Search 完成后得到的“候选框”在特征图上的映射。这里还是不讲人话，先简单提一下，ROI 可以认为是图上有用的部分。<br>@搞一页来讲一下 ROT 与 Mask-RCNN</p><p>对于图像部分，作者用在客观检测任务中预训练的 Mask-RCNN 模型来提取新闻图像的 ROI，进一步使用 ResNet-50 模型来提取 ROI 的特征，形成一个特征序列 [ep1, ep2, ep3 … epk]，其中 k 为 ROI 的数量。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220331195301.png" class="" title="ROI提取" alt="ROI提取"><p>其输出是一个 ROI 的深度表示。</p><h3 id="ViLBERT"><a href="#ViLBERT" class="headerlink" title="ViLBERT"></a>ViLBERT</h3><p>直观来说是用独立的模型对新闻文本和图像进行建模。然而，同一新闻的标题和图片通常有一些相互之间的关系。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220330154658.png" class="" title="News with images for news recommendation" alt="News with images for news recommendation"><p>这张新闻图片图1的 “Fauci” 和他的照片就相关，通过发掘潜在的标题-图片相关性，作者认为能更好地用于推断用户兴趣。</p><p>视觉语言学模型可以有效地对文本和图像之间的跨模式关系进行建模。</p><p>因此作者将 ROI 部分的特征序列，即 ROI 代表的信息本身，加上标题的单词序列，输入 ViLBERT 视觉语言学模型。<br>@搞一页来讲一下 ViLBERT</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401082511.png" class="" title="编码器架构" alt="编码器架构"><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>针对 ViLBERT 的输出，ROI 部分的特征序列 Hp =  [hp1, hp2 … hpk] 与词表示序列 Ht = [ht1, ht2 … htm]，作者使用了一个单词注意力网络来学习标题表示、一个图注意力网络来学习图表示：</p><p>标题表示：Wt 是一个参数矩阵，qt 是一个注意力查询向量</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401102340.png" class=""><p>最后，标题的最终表示等于原表示乘上注意力权重， rt = Rt * at<br>ROI 的注意力权重也是类似的，Wp 是参数，qp 是注意力查询向量</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401102516.png" class=""><p>图片的最终表示等于原 ROI 表示乘上注意力权重， rp = Rp * ap</p><h2 id="多模态新闻推荐"><a href="#多模态新闻推荐" class="headerlink" title="多模态新闻推荐"></a>多模态新闻推荐</h2><p>本节讲的内容实在是太少了，也不知道作者怎么水一页的，但是我要汇报，也许要水两页，所以…</p><h3 id="用户兴趣建模"><a href="#用户兴趣建模" class="headerlink" title="用户兴趣建模"></a>用户兴趣建模</h3><p>和以往的推荐一样，作者从用户的历史点击中来学习用户的兴趣。<br>并不是用户点击的所有新闻都对用户兴趣的建立有促进作用。<br>候选新闻可能与被点击新闻有一些跨模式的关系，比如候选图片与被点击标题。</p><p>@这里再说一说impression、session、cookie、user等概念吧</p><p>首先，以前点击过的新闻的标题和图片表示<br>Rt = [rt1, rt2 … rtp]<br>Rp = [rp1, rp2 … rpp]  – 我一定找时间补一下 Markdown 怎么写公式</p><p>然后，候选新闻的标题和图片表示，rtc, rpc  (c - candidate)</p><p>那么，用户兴趣用几方面的 softmax 连结起来</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401111207.png" class="" title="用户兴趣表示"><h3 id="新闻点击预测"><a href="#新闻点击预测" class="headerlink" title="新闻点击预测"></a>新闻点击预测</h3><p>由上节，候选新闻的标题、图片表示，rtc, rpc<br>有用户的兴趣表示 u</p><p>构建候选新闻推荐得分，y = rtc * u + rpc * u</p><p>使用负抽样技术，从新闻会话日志中建立标记样本。具体来说，对于每个被点击的新闻，随机选择同一会话中显示的𝑁个非点击的新闻，我们共同预测𝑁个+ 1 新闻的分数。通过 softmax 函数进一步标准化，将新闻点击预测问题重新表述为一个多分类任务，即预测哪条新闻被点击。使用交叉熵作为模型训练的损失函数。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者使用了一个<br>A dataset based on the logs collected from the Microsoft News website during three weeks (from Feb. 25, 2020 to Mar. 16, 2020)<br>说实话这个可能是我认为本文唯一的贡献了，然而作者不公开。</p><p>这里谈谈 Mind 数据集有什么问题：Mind 有详尽的文本信息、同时也有一个 Scrapy 脚本可以获取全文数据确实，但是 Mind 数据中指向的链接已经是 Archive 类型链接了，图片缓存已经没有了 404。第二，Mind 数据集虽然分了 dev/train/test，而且还很贴心的给了前期开发用的小型数据集，但是 issue 中指出 Mind 数据集中的 test 缺少数据标签，没办法 evaluate ，所以还是需要自己划分 train/test。</p><p>说回来，这里是作者的数据集。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401151935.png" class="" title="dataset" alt="dataset"><p>黄色数据部分是我们搞不到的数据。</p><p>第一周的日志被用来构建用户历史，其余会话被用来形成点击和非点击样本。按时间对这些会话进行排序，前100万个会话用于训练，后 10 万个会话用于验证，其余用于测试。</p><h2 id="Comparison-with-baselines"><a href="#Comparison-with-baselines" class="headerlink" title="Comparison with baselines"></a>Comparison with baselines</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401152608.png" class="" title="Performance comparison of different methods" alt="Performance comparison of different methods"><h2 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h2><p>变体1：考虑标题+图片、只考虑标题、只考虑图片</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401153001.png" class="" title="Effectiveness of multimodal information" alt="Effectiveness of multimodal information"><p>变体2：考虑共同注意力转换+候选新闻注意力、只考虑共同注意力转换、只考虑候选新闻注意力<br>is it necessary ?</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401153106.png" class="" title="Effectiveness of the co-attentional Transformers in ViLBERT and crossmodal candidate-aware attention" alt="Effectiveness of the co-attentional Transformers in ViLBERT and crossmodal candidate-aware attention"><h2 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h2><p>第一条: 正面相关，NRMS 没预测对但我们对了<br>第二条：不相关，NRMS 预测错了但我们预测得还行<br>第三条：完全没关系，大家都知道完全没关系</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220401153442.png" class="" title="case" alt="case"><h1 id="My-Slides"><a href="#My-Slides" class="headerlink" title="My Slides"></a>My Slides</h1><p>呀，理解不好，暂时这样看看吧</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_01.jpg" class="" title="1" alt="1"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_02.jpg" class="" title="2" alt="2"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_03.jpg" class="" title="3" alt="3"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_04.jpg" class="" title="4" alt="4"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_05.jpg" class="" title="5" alt="5"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_06.jpg" class="" title="6" alt="6"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_07.jpg" class="" title="7" alt="7"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_08.jpg" class="" title="8" alt="8"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_09.jpg" class="" title="9" alt="9"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_10.jpg" class="" title="10" alt="10"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_11.jpg" class="" title="11" alt="11"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_12.jpg" class="" title="12" alt="12"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_13.jpg" class="" title="13" alt="13"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_14.jpg" class="" title="14" alt="14"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_15.jpg" class="" title="15" alt="15"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_16.jpg" class="" title="16" alt="16"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_17.jpg" class="" title="17" alt="17"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_18.jpg" class="" title="18" alt="18"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/PPT_%E9%A1%B5%E9%9D%A2_19.jpg" class="" title="19" alt="19">]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>新闻推荐</tag>
      
      <tag>图像嵌入</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MIND:A Large-scale Dataset for News Recommendation</title>
    <link href="/2022/03/10/wannot-readpaper-0002/"/>
    <url>/2022/03/10/wannot-readpaper-0002/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>新闻推荐</tag>
      
      <tag>数据集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>「无用」洗毛衣的时候所想</title>
    <link href="/2022/03/07/sweater-thought/"/>
    <url>/2022/03/07/sweater-thought/</url>
    
    <content type="html"><![CDATA[<blockquote><ul><li>你知道我们这栋楼自来水温最冷的时候是什么时候吗？</li><li><ul><li>现在吗？(下午 14:20)</li></ul></li><li>是晚上九点到十一点的时候哦。</li><li><ul><li>难道不应该是早上吗？</li></ul></li><li>早上的话，整栋楼水管中的水，半夜经过暖气的余温加热，反而会有点暖和；白天的话经过太阳加热，非常暖和；反而是晚上九十点，夜晚剥夺走了太阳的温度，大家又把水管里原有的水用完了，所以流出来的水会非常冷哦。</li><li>所以说午后这个时间，洗衣服什么的非常的惬意。</li><li>这些，都是经过我日复一日地，半夜洗袜子和早起洗头发，总结出来的结论。</li></ul></blockquote><p>毛衣是我最不喜欢洗的几种衣服之一，因为我可能相当懒惰(但是对洗衣服这件事又很在意)吧。</p><p>毛衣是几种不能机洗的衣服之一，一定要用暖和的水，慢慢加上洗衣液，轻轻洗去不干净的地方，小心弄干，再小心晾晒。</p><p>不暖和的水，是没有办法让毛衣迁就给你洗的。</p><p>毛衣吸了水之后会变得相当重，很难拧干 ———— 当然拧这种粗暴的方式也是不行的。</p><p>晾晒如果不注意的话，毛衣就会拖成一长条，或者皱成一片。那样就简直没法穿啦。</p><p><em><strong>简直就是麻烦的女友</strong></em></p><p>不过有时候我也会在想，两个人的关系就像穿毛衣一样吧。穿着漂亮的毛衣，或者是看上去高质感的毛衣，走到哪里都会迎来柔和的目光吧。真是说呢，馬子にも衣裳，人要衣装佛要金装。</p><p>再好看的毛衣，穿几次之后也需要保养吧，越是好的毛衣越会费心保养，这也是人之常情吧。洗毛衣的时候，就会觉得很麻烦~ 但是，承受着穿毛衣的享受，和承担着洗毛衣时候的辛苦，生活就是要这样前进吧。</p><p>有的人适合穿可爱的毛衣，有的人适合穿气派的毛衣，有的人适合穿整洁严肃的毛衣。</p><p><em><strong>一开始穿毛衣的时候，我并不会想到这些事情</strong></em></p><p>买一件新毛衣的时候，也许不合身，也许在常规搭配上并不合适，买毛衣要考虑到很多事情</p><p>曾经有一件还不错的毛衣，对我来说略有点大，但是配衣服穿还比较合适</p><p>后来那件毛衣逐渐疏于保养，闷在衣柜里呆了好久，再后来一次错误的洗涤 + 晾晒之后</p><p>毛衣和我彻底分手了</p><p>这就教会了我，小心对待毛衣的方式</p>]]></content>
    
    
    
    <tags>
      
      <tag>Thoughts</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AML-1 Free Talk</title>
    <link href="/2022/03/02/AML-1-free-talk/"/>
    <url>/2022/03/02/AML-1-free-talk/</url>
    
    <content type="html"><![CDATA[<h1 id="1"><a href="#1" class="headerlink" title="1"></a>1</h1><p>The most important evaluation metric for machine learning is?<br><em>A. Generalization  B. Interpretability  C. Computation Cost  D. Memory</em></p><p>I think “A Generalization” since it’s the purpose of why we train a model. Interpretability also important but still can be move aside. For example in some very large model. GPT-2 ? or so. Computation cost and Memory is more and more less import since the development of the computation hardware.</p><h1 id="2"><a href="#2" class="headerlink" title="2"></a>2</h1><p>Logistic regression is used for?<br><em>A. regression task  B. classification task  C. clustering task  D. supervised learning</em></p><p>let’s refer the introduction of LR on sciencedirect</p><a href="https://www.sciencedirect.com/topics/computer-science/logistic-regression" title="" target="">computer-science&#x2F;logistic-regression</a><p>LR most used for binary classfication, since its output range between 0 to 1. It’s nolinear relation、conditional probability loss function and special output range, i think not quite fit for regression. clustering is non-supervised learning, also not applicable.</p><h1 id="3"><a href="#3" class="headerlink" title="3"></a>3</h1><p>When we deal with the missing data, which descriptions are correct?<br><em>A Discard the samples with missing features from the training data</em><br>Sometimes i do so<br><em>B Fill the missing features with the mean of the known values</em><br>That’s alse true. Interpolation.<br><em>C Fill the missing features with the median value is better than that of the mean value</em><br>Can’t say that. We don’t know the samples’ distribution. Mean values may better some occasions.<br><em>D All the missing values should be filled if we want to train a good model</em><br>Need not to do that. Since some attributes we dont use at all. And blank also means quite significant to some models.</p><h1 id="4"><a href="#4" class="headerlink" title="4"></a>4</h1><p>In machine learning, the word  “feature” and “attribute” are same.</p><p>Have you ever heard of “Feature Engineering”, we delete needless attributes、clean the data、analyze the relation to the y value and so on. Then the rest of those attributes we call “features”</p><h1 id="5"><a href="#5" class="headerlink" title="5"></a>5</h1><p>Ideally, driverless vehicles is an example of General AI.<br>No. For Driverless vehicle model, we still need to pre-define the rules. That is not what we call “General AI”</p><p>“General AI! Please help me do the homework!”<br>“Yes, master. It’s done!”<br>That’s a General AI.</p><p><strong>Sadily, After i submit the homework. the answer told me that</strong><br><strong>“driverless vehicles” is a General AI.</strong><br><strong>Im so depressed</strong></p><p>After i reviewed, i still think driverless is a narrow AI. So be it.</p>]]></content>
    
    
    
    <tags>
      
      <tag>Thoughts</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>「自然辩证法」“绪论”和“马克思主义自然观”部分思考</title>
    <link href="/2022/03/02/dialectics-of-nature-free-talk/"/>
    <url>/2022/03/02/dialectics-of-nature-free-talk/</url>
    
    <content type="html"><![CDATA[<p><strong>1、关于科学文化与人文文化的融合，请结合你的专业背景谈谈自己的观点。</strong><br>胡塞尔在《欧洲科学危机和超验现象学》中指出，从文化中独立出来的科学，“抽象掉了作为过着人的生活的人的主体，抽象掉了一切精神的东西，一切在人的实践中的物所富有的文化特征”，科学文化与人文文化的对立，使得二者都走向了几乎破碎的局面。从需求层次理论来看，现代社会，科学技术提供了丰富的物质基础，而人文文化的复兴则给予了人类精神和情感上的满足，二者融合，互相学习取舍，给人类社会学的发展起到了推动作用。以数据科学的视角观察，传统的数据科学更多从数据技术的视角，将人的个体视作奇点，广泛地研究群体行为，而更现代的数据科学考虑了个体行为，将消费者行为分析、心理学等社会学内容吸纳，产生了个性化用户肖像技术等等关注于人的个体的研究领域。</p><p><strong>2、恩格斯的《自然辩证法》中有哪些论述令你印象深刻？谈谈自己的理解。</strong><br>《自然辩证法》一书力图通过研究自然科学发展来揭示自然界的辩证法。主要谈谈我关于恩格斯的辩证唯物主义自然观的认识，《自然辩证法》提出辩证唯物主义自然观，既强调了自然的客观存在和发展变化，又展示了人类实践改造的作用，体现了人类社会和自然的联系与发展。从切身体会出发，我的家乡是“两山”理论提出地，浙江湖州。十余年来，湖州市仿佛经历了一个“迷惘，探索，到振兴”的阶段。两山理论刚提出时，湖州市经济主要依托传统小手工制造业为基础，规模小秩序差效益低；在两山理论的指导下，湖州市政府开始研究当地自然环境提供的特有优势，以改造安吉、德清为主的绿色乡村计划为核心，打造一系列绿色农业、绿色旅游业；开发环太湖带经济区，主打高新技术产业；改造乡村聚落，打造具有江南特色的旅游小镇文化。在把握准湖州市自然环境特点后，针对提出了大致上述经济发展规划，也使得近年来，湖州市经济增速一度上升到浙江省前三的位置。</p><p><strong>3、科学技术的发展与自然观的关系是什么？</strong><br>恩格斯讲过：“在从笛卡尔到黑格尔和从霍布斯到费尔巴哈这一长时期内，推动哲学家前进的，决不像他们所想象的那样，只是纯粹思想的力量。恰恰相反，真正推动他们前进的，主要是自然科学和工业的强大而日益迅速的进步。”以辩证唯物主义的视角来看，自然观对科学技术的发展具有重要的指导意义，事实上，古代近代的科学技术发展，正是伴随着人们对自然一步步探索深入认识的过程而发展；从科学技术发展对于自然界，以及自然观的改造作用来看，科学技术发展的每一个阶段，都给了人类社会更高的改造自然界的能力，人类社会对自然界的认识也正是如此，进入了到超宏观和超微观的层面，而这样改造自然的行为，也加深了人类社会对自然界的认识，更加地丰富和发展了自然观。</p><p><strong>4、你如何评价现代人类中心主义和非人类中心主义？</strong><br>首先应该强调，现代人类中心主义和非人类中心主义都包含协调人与自然关系发展的观点，都承认人类发展自身利益也要合理对待自然。现代人类中心主义是以人类共同、长远利益出发，认为自然没有内在价值，一切需要以人的利益为核心，即使是保障自然的行为，也是为了人类社会长远利益而考虑。非人类中心主义则认为道德关怀的对象不应限制于人类本身，以中国一句老话讲即“世间万物皆有灵”。两种理论都具有其合理性，就我个人而言更偏向现代的人类中心主义，就人类社会发展历程来看，人类社会发展都是伴随着人类认识改造自然界进行的，现代人类社会发展也是如此，发展过程中一定会遇到人类社会问题与自然对立的情况，作为人类社会的一员，我认为应以人类社会核心、长远利益为先。</p><p><strong>5、科学技术解决环境问题是否有限度？</strong><br>科学技术解决环境问题，可以理解为发展科技解决现有环境问题，但是也有一层先发展，等科学技术提升到一定层次后治理环境问题的意思存在。因此对于科学技术解决环境问题的限度，只能说期待，但不依赖。从自然辨证唯物主义来看，自然科学的发展确实能提高人类社会改造自然的能力，但是也要承认在人类社会的每一个阶段，改造自然的能力都是有限的。因此我们不能依赖着未来某项关键科技完全扭转环境污染的局面的想法，但是要不断探索发展科学技术，为现有或将来的环境问题做好对策。</p><p><strong>6、如何评价传统的经济增长观或发展模式？</strong><br>传统的经济增长观，从辩证唯物主义的观点来看，是一种孤立静止的经济增长观。传统经济增长认为经济发展到一定程度就完全有余力解决产生的环境问题，并没有考虑到经济增长后需求随之增长的动态变化，也没有考虑到环境问题发酵严重化的动态变化，是一种在现在被否定的经济发展模式。传统的经济增长观，只能说在某些历史阶段，由于人类社会自然观发展不足，或者社会形式需要不得不采取的经济发展下策。</p><p><strong>7、谈一谈你对“两山”理论的理解。</strong><br>“两山”理论完美地诠释了辩证唯物主义自然观中，既强调自然的客观存在和发展变化，又展示了人类实践改造的作用，体现了人类社会和自然的联系与发展的观点。从切身体会出发，我的家乡是“两山”理论提出地，浙江湖州。十余年来，湖州市仿佛经历了一个“迷惘，探索，到振兴”的阶段。两山理论刚提出时，湖州市经济主要依托传统小手工制造业为基础，规模小秩序差效益低；在两山理论的指导下，湖州市政府开始研究当地自然环境提供的特有优势，以改造安吉、德清为主的绿色乡村计划为核心，打造一系列绿色农业、绿色旅游业；开发环太湖带经济区，主打高新技术产业；改造乡村聚落，打造具有江南特色的旅游小镇文化。在把握准湖州市自然环境特点后，针对提出了大致上述经济发展规划，也使得近年来，湖州市经济增速一度上升到浙江省前三的位置。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Thoughts</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Re:从零开始的硕士毕业设计思路</title>
    <link href="/2022/03/01/my-paper/"/>
    <url>/2022/03/01/my-paper/</url>
    
    <content type="html"><![CDATA[<p>おや　みんな！</p><p>这篇文章动笔于 Mar-3，动笔的动机在于总结一下“在暴风雨中”一般的假期，虽然有按照完美的作息工作休息，但是学习的内容，特别是关于毕业设计的内容“被吹得”七零八落，正好趁这次总结问一下自己，文章到底怎么办。虽然之前也有了解一些内容了，但是没有里程碑式的材料，所以也可以说是「从零开始的硕士毕业设计」。</p><h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>先简单交代一下，要研究的题目是老题目了，新闻推荐系统。个人想做的原因有几个：<br>一、本身是阅读党，有关注一些 RSS，也会关注一些被推送的新闻，对于被推送一些不喜欢的新闻也很困扰，因此对新闻推荐系统抱有了额外的兴趣；<br>二、关注的很多算法大神、资讯栏目很多讲到推荐系统算法，也学到了一些；<br>三、前段时间精读了一些关于新的推荐系统新闻数据和算法的文章，很想尝试一下；<br>四、有朋友想研究，正好我在别的方面也没什么想法</p><h1 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h1><p>先放着暂时不想写，由于这个课题是比较常见的，意义什么的比较容易准备吧。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>新闻有很强的时效性。新闻平台每天会产生大量新的新闻，而已有的新闻会快速消失。这带来了严重的冷启动问题，并导致许多如协同过滤等基于 ID 来表示用户和待推荐物品的推荐方法无法使用；</p><p>其次，很多现有的推荐系统使用如 ID 等人工设计的特征来表示待推荐物品。但是，新闻文章具有丰富的文本，并且这些文本包含重要的内容信息。推荐系统需要从新闻文本中了解新闻内容，不能简单地使用 ID 等特征来表示新闻；</p><p>第三，准确地建模用户对新闻的兴趣存在挑战。用户的兴趣通常比较多样并随时间动态演化，需要基于大量的用户反馈行为来挖掘和建模。然而新闻平台上往往不具有显式的用户反馈，甚至许多用户的隐式反馈也十分稀疏。因此，新闻推荐是一个重要并具有挑战性的研究课题。</p><p>【微软亚洲研究院】</p><h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>近年来，学术界和工业界的研究人员提出一些基于深度学习的新闻推荐方法，如 Embedding based News Recommendation 等。但这些方法通常是在私有数据集上设计和验证的，这使得其他研究人员难以对这些方法进行验证并提出改进。</p><p>很多推荐任务如产品推荐、电影推荐和餐厅推荐等通常有一些公认的基准数据集，例如 Amazon、MovieLens、Yelp 等。然而在新闻推荐领域高质量的基准数据集比较匮乏，严重制约了这一研究领域的进展。目前 <strong>仅有少数几个公开</strong> 的新闻推荐数据集，例如 Plista、Adressa、Globo 和 Yahoo! 等。但是，这些数据集存在一些限制。例如，它们 <strong>大部分不是英文数据集，并且其中一些规模很小，或者新闻信息不完整</strong>。</p><p>【微软亚洲研究院】</p><img src="https://pic4.zhimg.com/v2-843ca3b4b426751db7e529955d9d719b_b.png" class="" title="已有的若干公开新闻推荐数据集"><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>这里展示一些常见的通用推荐算法、新闻推荐算法、特性、来源等等材料。<br>(注：这里的常见值得是应用比较宽的推荐方法，并不是指最一般的推荐算法，因为那些方法用于新闻数据集基本效果很差)</p><p>常见/通用算法，以人工设计的形式表示新闻特征和用户特征(协同过滤等思路)<br>新的新闻推荐算法使用自然语言模型从新闻文本中学习新闻内容表示，并使用神经网络从过去点击过的新闻中学习用户兴趣表示，设计端到端训练</p><table><thead><tr><th>算法</th><th>特征</th><th>实验</th><th>来源</th></tr></thead><tbody><tr><td><em><strong>常见推荐算法</strong></em></td><td>😺</td><td>😺</td><td>😺</td></tr><tr><td>FM</td><td>基于因式分解机的经典推荐方法，使用用户ID、新闻ID、先前点击的新闻、候选新闻中提取的内容特征</td><td>√</td><td>Steffen Rendle. 2012. Factorization machines with libfm. TIST, 3(3):57:1–57:22.</td></tr><tr><td>DSSM</td><td>深度结构化语义模型，使用三格哈希和多层前馈网络进行匹配，应该是基于内容范式的方法</td><td>√</td><td>Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng,Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In CIKM, pages 2333–2338.</td></tr><tr><td>Wide＆Deep</td><td>双通道网络推荐，基于内容范式的方法</td><td>√</td><td>Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide &amp; deep learning for recommender systems. In DLRS, pages 7–10. ACM.</td></tr><tr><td>DeepFM</td><td>综合了深度网络和因子机(what’s this)，基于内容范式</td><td>√</td><td>Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. Deepfm: a factorizationmachine based neural network for ctr prediction. In AAAI, pages 1725–1731. AAAI Press.</td></tr><tr><td><em><strong>新闻推荐算法</strong></em></td><td>😺</td><td>😺</td><td>😺</td></tr><tr><td>DFM</td><td>使用了一个概念性的深度网络，以捕捉特征之间复杂的相互作用？？</td><td>√</td><td>Jianxun Lian, Fuzheng Zhang, Xing Xie, and Guangzhong Sun. 2018. Towards better representation learning for personalized news recommendation: a multi-channel deep fusion approach. In IJCAI, pages 3805–3811.</td></tr><tr><td>GRU</td><td>使用GRU网络从点击的新闻序列中学习用户表征</td><td>√</td><td>Shumpei Okura, Yukihiro Tagami, Shingo Ono, and Akira Tajima. 2017. Embedding-based news recommendation for millions of users. In KDD, pages 1933–1942. ACM.</td></tr><tr><td>DKN</td><td>使用CNN进行词嵌入的网络</td><td>√</td><td>Hongwei Wang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018. Dkn: Deep knowledge-aware network for news recommendation. In WWW, pages 1835–1844.</td></tr><tr><td>NPA</td><td>具有个性化关注机制的网络</td><td>√</td><td>Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang, and Xing Xie. 2019b. Npa: Neural news recommendation with personalized attention. In KDD, pages 2576–2584. ACM.</td></tr><tr><td>NAML</td><td>多视角学习的网络新闻推荐方法</td><td>√</td><td>Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang, and Xing Xie. 2019a. Neural news recommendation with attentive multiview learning. In IJCAI-19, pages 3863–3869.</td></tr><tr><td>LSTUR</td><td>长、短期用户兴趣，从最近点击的新闻中用GRU建立短期用户兴趣模型，并从整个点击历史中建立长期用户兴趣模型</td><td>√</td><td>Mingxiao An, Fangzhao Wu, Chuhan Wu, Kun Zhang, Zheng Liu, and Xing Xie. 2019. Neural news recommendation with long-and short-term user representations. In ACL, pages 336–345.</td></tr></tbody></table><p>传统方法，LDA 和 TF-IDF 等，加上 CNN、LSTM 和多头自注意力机制等基于深度学习的文本表示模型，理解新闻内容。 BERT 等预训练语言模型。</p><table><thead><tr><th>算法</th><th>特征</th><th>实验</th><th>来源</th></tr></thead><tbody><tr><td>LDA</td><td>使用一个概念性的网络来结合具有不同深度的神经网络深度的神经网络，以捕捉不同特征之间复杂的相互作用</td><td>√</td><td>MS</td></tr><tr><td>TF-IDF</td><td>传统方法，评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加</td><td>√</td><td>MS</td></tr><tr><td>CNN</td><td>不用说了老熟人</td><td>√</td><td>MS</td></tr><tr><td>Self-Att</td><td>不用说了老熟人</td><td>√</td><td>MS</td></tr><tr><td>LSTM</td><td>不用说了老熟人</td><td>√</td><td>MS</td></tr></tbody></table><p>同时使用多种新闻文本（例如标题、摘要、正文、类别和命名实体）往往比单独使用某一种新闻文本更好地理解新闻内容</p><p>那么。图片？</p><p>那么。图片+标签？</p><p>微软亚洲研究院也承认，未来我们计划将新闻中的图像和视频信息以及不同语言的新闻条目加入到 MIND 数据集中，以支持多模态和多语言的新闻推荐的研究。</p><p>那么为什么我们不做这件事情。</p><h1 id="创新"><a href="#创新" class="headerlink" title="创新"></a>创新</h1><p>要说文章有什么创新的话，我大概归纳到以下几点：</p><ol><li>数据创新，MIND 数据集刚问世不久(2020)，但是又大又全又有质量保障，是一个值得探索的数据集</li><li>方法上，MIND 数据集没有图片，但是提供了新闻链接，所以通过 CSCNN+图片+新闻标签+title+摘要+body的形式，应该能嵌入足够的很好的信息<br>粗略随便估算了一下，新闻数据+爬取图片数据内容，大约会占 250GB 的空间，这个规模应该还能够处理</li><li>架构上，没有在线的 A/B Test，但是通过 CSCNN 进行 early infusion 的形式，在新闻推荐的应用上应该是第一次<h2 id="数据-1"><a href="#数据-1" class="headerlink" title="数据"></a>数据</h2>新闻推荐数据集 Microsoft News Dataset，简称 MIND。MIND 数据集是从六周内 Microsoft News 用户的匿名化新闻点击记录中构建的，它包含16万多条新闻条目，1500 余万次展示记录，以及来自100万匿名用户的2400余万次点击行为。在 MIND 数据集中，每个新闻条目都具有丰富的 <strong>文本信息</strong>，例如标题、摘要、正文、类别和实体。<img src="https://pic3.zhimg.com/v2-7d22ddeb0171205eed7d9aa8760cf286_b.jpg" class="" title="MIND 数据集统计数据"></li></ol><p>MIND 数据集中新闻标题、摘要和正文的长度分布，新闻标题通常很短，而新闻正文则比较长。另外，大约85％的新闻文章自首次出现算起，大约在两天后将不再显示在新闻主页上，表明新闻信息在网络新闻平台的更新速度很快(这意味着我们要花相当的心思给冷启动，这也是为什么我希望通过图片再吸收信息的原因)</p><img src="https://pic1.zhimg.com/v2-78aae97cb47f3e1910996d0ea73c5c94_b.jpg" class="" title="MIND 数据集中新闻标题、摘要和正文的长度分布以及新闻生存时间的分布"><p>MIND 数据集中的每个样本都组织为[UserID, Timestamp, ImpressionLog, ClickHistory]的格式。UserID 和 Timestamp 表示一组新闻在时间 Timestamp 展示给了目标用户 UserID。ImpressionLog 包含了这组新闻中具体包含的新闻及用户和他们的交互行为（点击或不点击）。ClickHistory 是该用户过去点击过的新闻文章的序列</p><img src="https://pic3.zhimg.com/v2-2a2917e84e65f40a8ddfe022cf5883b6_b.jpg" class="" title="MIND 数据集中的一个样本示例"><p>MIND 数据集同时提供了新闻条目的详细信息。每个新闻都有 ID、URL、标题、摘要、类别和命名实体信息。</p><p>此外，微软提供了一个可以从 URL 对应的新闻网页抓取和解析新闻正文内容的工具。<br>这正是我所需要的。<br>这里展示了一个示例新闻。对于新闻中出现的命名实体，MIND 数据集还提供了从公开知识图谱预训练的实体及其关系的嵌入向量，以促进知识增强的新闻推荐方法的研究。</p><img src="https://pic1.zhimg.com/v2-37290cddd41b44e4db3cfe6948366f0c_b.jpg" class="" title="MIND 数据集中的一条示例新闻"><h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p>方法的话，就不得不提到之前读的另一篇论文了。</p><a href="/2022/02/20/wannot-readpaper-0001/" title="Category-Specific CNN for Visual-aware CTR Prediction at JD.com">Category-Specific CNN for Visual-aware CTR Prediction at JD.com</a><p>推荐系统下，专门针对电商方面，图像广告投放与 CTR 预测研究的 CSCNN 模型，早期的 CPC 推荐系统中，研究表明结合视觉特征，与非视觉特征(如类别标签、用户信息等)融合在一起预测，会起到更好的效果，当然用户也更能接受视觉信息投放的广告(attractive)；现在很多方法用的传统现成的(off-the-shell)CNN 来提取视觉特征。通过「图片+标签+early fusion」的模式，JD.com 已经通过真实的实验和 A/B Test 验证了有效性。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221131705.png" class="" title="Structure of CTR Prediction System"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221141056.png" class="" title="CSCNN"><p>选用 CSCNN 的原因大概在以下几点：</p><ol><li>CSCNN 要求需要有「标签 Category」，这点 JD 的数据、Mind 数据都是满足的。</li><li>JD 的数据和 Mind 数据相似，都有显著的长尾效应</li></ol><table><thead><tr><th><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220303111849.png" class="" width="470" height="350"></th><th><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221173931.png" class="" width="280" height="350"></th></tr></thead></table><p>一幅图说明的是新闻的热点时间也就一天多一点，另一幅图说明的是电商广告热点频率很低，从某种意义上，这二者说的意思一致。<br>3. CSCNN 对传统 CNN 进行兼容性改进，不过由于知名度、需要标签等使用的人还比较少，找到一份开源代码实现</p><h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h3><p>JD 的数据集是广告内容，文本信息其实不多，因此京东的 DCN 网络在处理文本材料时，仅仅使用了很简单的嵌入层。</p><a href="https://yunchaozheng.github.io/2022/02/20/wannot-readpaper-0001/#Non-visual-Feature-Embedding" title="" target="">Non-visual-Feature-Embedding</a><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221194153.png" class="" title="Non-visual-Feature-Embedding"><p>这样子的话在新闻推荐上貌似不行的，新闻推荐方面文本信息包含了相当大的知识，而微软的论文 <a href="https://msnews.github.io/assets/doc/ACL2020_MIND.pdf" title="" target="">MIND</a> 中也指出了，加入「标题+摘要+正文+类别+命名实体」这样完全的信息(命名实体还不知道是什么东西)，采用高级的文本嵌入方式能取得更好的表现，因此本研究在设计的时候也考虑采用完全的文本信息，考虑一下微软推荐的采用微调预训练的 BERT(这里有点难点就是暂时不清楚微软是怎么调整的)。</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>先随手拼了一下 CSCNN 和 BERT 的图，大致的意思是在预测 CTR 的时候，保留主体简单但 robust 的 DCN 网络结构大致不变，取消原本因为线上系统性能需要的 LookupTable(这个举措好不好呢？写文章的时候觉得又有必要保留下来节省性能)；CSCNN 的主体结构大致也不变，输入图片和类别标签从 Mind 数据集或者爬取</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220303130730.png" class="" title="Structure"><p>调整原本有点单薄的文本嵌入层，加上一层比较完整的 NLP 网络(这里就用 bert 示例)，这样 DCN 两端都是比较 state-of-art 的网络，做出来的效果应该会比较好。</p><h1 id="计划预估"><a href="#计划预估" class="headerlink" title="计划预估"></a>计划预估</h1><p>因为这个规模(从数据集规模，从工作量规模来说)的工作我也是第一次，并且平时有上课或者班级的杂事，暂且预估两个月的时间。</p><p>实验思路的话，我打算仿照京东的思路，做 state-of-art 对比、有无图片+标签嵌入对比、Hyper-Parameters finetune 程度对比这几组实验</p><table><thead><tr><th>时间 DDL</th><th>预计工作</th><th>备注</th></tr></thead><tbody><tr><td>Mar.15</td><td>Mind+图片爬取</td><td>图片很多，需要费一定功夫，并且入数据库</td></tr><tr><td>Mar.20</td><td>DCN Demo</td><td>DCN 是backbone 网络，作为大框架应该先被搭建完成</td></tr><tr><td>Mar.30</td><td>CSCNN</td><td>关于 CV 方面的知识我稍微懂一些，还是需要比较多的时间来完全搞懂 CSCNN 的知识</td></tr><tr><td>Apr.10</td><td>BERT</td><td>BERT 以前虽然有实践过，但是已经很久了并且任务也不太一样，还是需要比较多时间</td></tr><tr><td>Apr.15</td><td>拿掉CSCNN嵌入</td><td>单纯用新闻文本进行研究，虽然微软做过相关工作，但是还要亲自做一些比较实验</td></tr><tr><td>Apr.30</td><td>State-of-art-comparement</td><td>和比较新的新闻推荐算法对比，这又需要很多时间</td></tr></tbody></table><p>基本实验完成大概也需要两个月吧，后续大概还需要补充实验，加上写作，基本上这学期就用完了。</p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>推荐系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>远程打印指南</title>
    <link href="/2022/02/27/remote-print/"/>
    <url>/2022/02/27/remote-print/</url>
    
    <content type="html"><![CDATA[<p>这篇是开学后发现打印机设施不知道为什么不响应了，也不想追究原因而写的一篇曲线救国打印方法。<br>首先，讲述一下团队打印机以前采用过的方案，并分析一下优缺点。</p><h1 id="裸连时代"><a href="#裸连时代" class="headerlink" title="裸连时代"></a>裸连时代</h1><p>裸连时代，指的是用户直接使用 U 盘、移动硬盘等外置设备连接到打印机所在的终端上，然后操作打印机打印。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220227180938.png" class="" title="裸连时代"><p>裸连的好处在于丝滑无延迟的操控体验，然而因为终端的接口、显示功能都不是很好，而且在庞大、先进的实验室竟然做不到！！<br>我在座位上点一下，远端的打印机就把我要的文件吐出来这样充满优越感的操作<br>(当然不是因为放打印机的桌子刚好在我旁边)，<br>因此这个方案被我非常鄙弃。</p><h1 id="VPN-时代"><a href="#VPN-时代" class="headerlink" title="VPN 时代"></a>VPN 时代</h1><p>Windows 平台的共享打印机协议，在我们的校园网中是会被拦截的，网络与共享中心中也不会找到打印机所在的服务器，思考过后我提出了一个大胆的想法。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220227181913.png" class="" title="VPN 时代"><p>利用现有的校园网这一天然大局域网，我们将打印服务器(打印机物理连接的 WindowsServer 服务器)接入了校园网，在上面利用 WindowsServer 的基础设施启动了 VPN 服务，然后让需要连接打印的用户机器暂时连接 VPN 网络，即可进入加密隧道，形成紧密的局域网关系，让共享打印机实现成为可能。</p><p>然而，在保持运作数小时后，VPN 流量被校园网探测出来，并且截断了。<br>VPN 流量禁止，但是了解到 HTTP 流量是被允许的(因为我经常用 Jellyfin 在宿舍看实验室机器里存的电影，当然这是后话了)</p><h1 id="HTTP-时代"><a href="#HTTP-时代" class="headerlink" title="HTTP 时代"></a>HTTP 时代</h1><p>在悲催的，仅存在了数小时的 VPN 时代过去后，我们的打印机终于迎来了繁荣近半年(自称)的 HTTP 时代，进入了便捷(也没那么便捷)的点一下打印生活。</p><p>共享打印机信息封装在 HTTP 数据中，通过 IPP 连接的方式，被广泛装在团队各个电脑上，只要获得了正确的 IPP 地址、用户名、密码，就可以发送打印任务到打印机上。</p><table><thead><tr><th>项目</th><th>内容</th><th>解释</th></tr></thead><tbody><tr><td>IPP地址</td><td><a href="http://10.8.130.137:8888/candyprinter/.printer">http://10.8.130.137:8888/candyprinter/.printer</a></td><td>打印机安装地址</td></tr><tr><td>用户名</td><td>Administrator</td><td>安装用户名</td></tr><tr><td>密码</td><td>***</td><td>请当面问我</td></tr><tr><td>驱动</td><td><a href="https://10.8.130.137:7777/down/V9GFKgSfheku">https://10.8.130.137:7777/down/V9GFKgSfheku</a></td><td>驱动文件</td></tr></tbody></table><p>经过改进后，我们的打印机任务可以从校园网任何地方发起，因此在实验室打印非常便捷，当然也存在从食堂打印的潜力？</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220227183742.png" class="" title="HTTP 时代"><h2 id="HTTP-时代改"><a href="#HTTP-时代改" class="headerlink" title="HTTP 时代改"></a>HTTP 时代改</h2><p>后期当我们获得了一架服务器(用作 Docker 服务器那个，下称 Docker 服务器)以及校园网的静态地址后，改进方案来了。</p><p>以前的 HTTP 打印方式，由于依赖打印服务器本身的 IP 地址，可惜这个地址是通过 DHCP 下发的，尽管一直连接着基本上不会变化，但改变的可能性依然存在。因此，我们的 HTTP 打印架构发生了以下的变化:</p><p>用户 — 用户电脑 — 打印服务器 — 打印机<br> —&gt;<br>用户 — 用户电脑 — Docker 服务器 — 打印服务器 — 打印机</p><p>解决的方案是利用 Frp 将打印服务器的 HTTP 端口映射到 Docker 服务器的 8888 端口，具体细节与 Frp 相关内容均重复，略过。</p><h1 id="RDP-时代"><a href="#RDP-时代" class="headerlink" title="RDP 时代"></a>RDP 时代</h1><p>RDP 时代存在意义是为了解决 HTTP 打印有时抽风的情况，利用 HTTP 打印时可能会出现，连接不上、连接延迟高、打印任务卡住、打印任务无法删除等等问题，这是因为一些未知的原因(这个该死的打印机驱动适配不好！本身体质欠佳！总之就是莫名其妙不是我的问题！)有时候需要手动重启打印机或者打印服务器，我把打印服务器(WindowsServer)的 RDP 也通过 Docker 服务器穿透了，作为我自己经常用的一种手段，在这里共享出来，作为日后解决方案的一种。操作方法如下:</p><ol><li>在开始菜单(或者通过搜索)打开“远程桌面连接”</li><li>计算机地址 “10.8.130.137”</li><li>用户名 “Administrator”</li><li>密码 “你来问我”</li></ol><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220227185731.png" class="" title="远程桌面"><ol start="5"><li>本地资源–详细信息–驱动器–勾选</li><li>连接，确定所有警告并连接</li><li>在远程桌面里，通过资源管理器就能找到用户电脑驱动器的文件，拷贝打印即可</li></ol><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220227185843.png" class="" title="远程驱动器"><h1 id="后注：常见问题解决方法"><a href="#后注：常见问题解决方法" class="headerlink" title="后注：常见问题解决方法"></a>后注：常见问题解决方法</h1><ol><li>提交打印后无响应<br>打印机从休眠启动时会出现“起床呆滞”现象，表现为启动后不打印的样子，解决方法就是长按电源键关机(6s 以上)，再启动</li><li>删除打印失败<br>打印机的驱动问题导致，解决方法，长按电源键关机(6s 以上)，并通过 RDP 方案重启打印服务器</li><li>Word、Excel 等软件卡住<br>罕见的 HTTP 打印机失联后，Word 等软件会保持等待打印机响应(通常会等待数十秒)，表现为软件卡住，解决方法是暂时删除 HTTP 打印机，直到我们认为打印机已经恢复</li><li>打印中断<br>因缺纸导致的中断，只要补纸后按一下电源键继续；因其他情况发生的打印中断，貌似在重启动后，提交下一个任务时，会先进行完毕中断前的任务，再执行后续任务(印象中)</li></ol><h1 id="后注2：CandyPrinter-安装方法"><a href="#后注2：CandyPrinter-安装方法" class="headerlink" title="后注2：CandyPrinter 安装方法"></a>后注2：CandyPrinter 安装方法</h1><p>CandyPrinter 是团队仅有的一台激光黑白打印/扫描机，产品是 Lenovo M7268，虽然说他经常出现各种问题，比如罢工啊，卡纸啊，“花式打印”啊，但是这是我们仅有的一台打印机了。将 CandyPrinter(仅打印功能)安装到个人电脑的流程如下：</p><ol><li>个人电脑连接至 DUT 的集团网路，不建议在个人笔记本安装 CandyPrinter，因为个人笔记本离开 DUT 网路后，很容易造成“继续努力找到 CandyPrinter” 从而导致某些软件在一段时间内卡死。</li><li>在设置里找到打印机相关选项，Windows11/10 是在设置-(设备)蓝牙和其他设备，启动到打印机设置选单</li><li>点击添加打印机，并且等待一会，出现“我需要的打印机不在列表中 – 手动添加”</li></ol><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220307085736.png" class="" width="600" height="180" title="手动添加1"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220307090110.png" class="" width="640" height="540" title="手动添加2"><ol start="4"><li>正如上图中展示的，在“按名称选择共享打印机”中手动填写打印机的地址:<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">http:<span class="hljs-regexp">//</span><span class="hljs-number">10.8</span>.<span class="hljs-number">130.137</span>:<span class="hljs-number">8888</span><span class="hljs-regexp">/printers/</span>candyprinter/.printer<br></code></pre></td></tr></table></figure></li><li>下载打印机的驱动文件，可以尝试我们的内网地址: <a href="https://10.8.130.137:7777/down/V9GFKgSfheku" title="" target="">M7268_Series_drivers_Win_20210518163312.7z</a><br>如果上述网址失效，可以尝试联想官方的公网地址: <a href="https://lenovo-upload.oss-cn-beijing.aliyuncs.com/drivers/M7268_Series_drivers_Win_20210518163312.7z" title="" target="">M7268_Series_drivers_Win_20210518163312.7z</a></li><li>使用 <a href="https://www.7-zip.org/" title="" target="">7-zip</a> 等压缩软件解压，获得一个 exe 文件(它其实也是一个压缩包)，继续用压缩软件打开它并解压，这样我们可以避免安装不必要的软件，仅使用驱动文件。</li><li>解压后，得到如下一个文件夹及内部内容，保留先不要动<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs livescript">.<span class="hljs-string">\LenovoABC_Plus_M7268&amp;M7268W_FC012\</span><br>    <span class="hljs-string">\Application</span>        <span class="hljs-comment"># .NetFramework 4.0 installation wizard</span><br>    <span class="hljs-string">\M7268&amp;M7268W</span><br>        <span class="hljs-string">\Drivers</span><br>            <span class="hljs-string">\HB</span><br>                <span class="hljs-string">\Win_87VistaXP</span><br>                    <span class="hljs-string">\x32</span><br>                    <span class="hljs-string">\x64</span><br>                        <span class="hljs-string">\English</span><br>                        <span class="hljs-string">\SimplifiedChinese</span><br>                            <span class="hljs-string">\LNTHR5Z.cab</span><br>                            <span class="hljs-string">\lnthr5z.cat</span><br>                            <span class="hljs-string">\LNTHR5Z64.inf</span>          <span class="hljs-comment"># 这是我们后面需要的</span><br>                        <span class="hljs-string">\LNTHR5Zcmmn.cab</span><br>            <span class="hljs-string">\Scanner</span><br>        <span class="hljs-string">\Install</span><br>        <span class="hljs-string">\SetupAssistance</span><br>        <span class="hljs-string">\Startup</span><br>        <span class="hljs-string">\AUTORUN.inf</span><br>        <span class="hljs-string">\setup.exe</span><br>        <span class="hljs-string">\setup.exe.manifest</span><br>        <span class="hljs-string">\setup.ini</span><br></code></pre></td></tr></table></figure></li><li>安装会需要驱动文件和用户名+密码<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">用户名: Administrator</span><br><span class="hljs-section">密码: (刮开此处获取密码 ---&gt; 密码怎么可能放在公网上呢)</span><br></code></pre></td></tr></table></figure></li><li>在打印机非休眠状态下，进行下一步安装后，初次安装会提示需要驱动文件，选择，从磁盘安装，到上面提到的“LHTHR5Z64.inf”文件安装即可，选择“M7268”型号，安装完毕</li></ol>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Frp</tag>
      
      <tag>RDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>streamlit-tryout</title>
    <link href="/2022/02/25/streamlit-tryout/"/>
    <url>/2022/02/25/streamlit-tryout/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Category-Specific CNN for Visual-aware CTR Prediction at JD.com</title>
    <link href="/2022/02/20/wannot-readpaper-0001/"/>
    <url>/2022/02/20/wannot-readpaper-0001/</url>
    
    <content type="html"><![CDATA[<h1 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h1><p>作者: Hu Liu, Jing Lu, Hao Yang 等<br>主要机构: JD.COM<br>来源: KDD 2020<br>提交时间: 2020-Jun-19<br>关键词: RS, category-specific CNN, architecture</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>在本文有关的 RS，通常说的就是 CPC 推荐系统。CPC，即 cost-per-click ，以每个投放(impression)的成本来衡量的推荐系统，衡量标准为 eCPM(effective cost per mille)，每千次投放带来的收益。而最终衡量投放有效性的，是 CTR(Click Through Rate)，即 click/impression，CTR 高代表这个投放是有效的。</p><p>CSCNN，即标题中提到的 Category-Specific CNN，是京东开发的结合图像标签先验知识的特定类别型 CNN。本文是推荐系统下，专门针对电商方面，图像广告投放与 CTR 预测研究的 CSCNN 模型，文章做了比较不错的性能测试和对比分析，当然背靠京东这棵互联网电商大树，京东的 CSCNN 研究人员做了足够的消融实验和对照实验。</p><p>首先讲一下，为什么京东要提出这个 CSCNN 模型。在早期的 CPC 推荐系统中，研究表明结合视觉特征，与非视觉特征(如类别标签、用户信息等)融合在一起预测，会起到更好的效果，当然用户也更能接受视觉信息投放的广告(attractive)；现在很多方法用的传统现成的(off-the-shell)CNN 来提取视觉特征。</p><p>讲到这里，就要提传统 CNN 在电商领域为什么不合适：<br>一、CNN 负责的任务是分类任务，简单来说，输入-判别，类别标签作为输出存在，电商领域的广告图像一般都具有标签，类别已经是确定的知识，电商领域的任务需求，是将这些标签也输入，最后要求提取出有助于 CTR 增长的视觉信息，用传统 CNN 浪费了很多潜在性能和表达能力在判别方面；<br>二、在真正在线的推荐系统中使用 CNN 也是不现实的，要 CNN 的性能跟上电商系统随时间输入的信息流，做到低延迟回复，做不到；<br>三、一些研究通过在 CNN 嵌入后的基础上用一些特定的投影矩阵来分解信息，这是一种事后处理的方法，文中成为 late fusion ，相比原来不处理肯定好，但是 CSCNN 提出了 early-fusion 处理的方式，效果更好。</p><h1 id="CTR-预测"><a href="#CTR-预测" class="headerlink" title="CTR 预测"></a>CTR 预测</h1><p>废话少说，直接开始正题好了。首先要放一下后面看到的一些符号的说明表。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221124508.png" class="" title="Important Notations Used"><p>CTR 实际上可以表示为在进行一次广告投放 impression 后能否发生正反馈(通常就是 click)的概率。</p><p>CTR 预测可以表示为一种二分类预测，最终目标是为了要学习一种 prediction function f: Rd -&gt; R，让数据拟合的 f 趋近真实的 R 的映射关系。D={(x1,y1)…(xd,yd)}，Rd={x1…xd}，yi={0,1} 表示 click 是否发生。</p><p>以如下负对数似然化表示的目标函数: </p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221131101.png" class="" title="negative log-likelihood object function"><p>y尖是预测的 CTR，最后通过 sigmoid 映射到(0,1)</p><p>这里看看整个 CTR 预测系统的架构图:</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221131705.png" class="" title="Structure of CTR Prediction System"><p>底下的 Xv 代表视觉特征的向量，由广告图片通过 CSCNN 提取或者通过 LookupTable 查找得到(为了节省时间，符合线上需求，CSCNN 把离线模型的图片特征，连同 AdID 都记录下来形成一个字典，在线系统通过查找字典避免了耗时计算)；Xnv代表非视觉特征的向量，如用户信息等，顶部一种修改过的 DCN(Deep Cross Network)将 Xv, Xnv 作为输入吸收，预测 CTR。</p><h1 id="DCN-Deep-Cross-Network"><a href="#DCN-Deep-Cross-Network" class="headerlink" title="DCN(Deep Cross Network)"></a>DCN(Deep Cross Network)</h1><p>Deep &amp; Cross Network. Deep &amp; Cross network (DCN) has achieved promising performance thanks to the ability to learn effective feature interactions</p><h2 id="Deep-Net"><a href="#Deep-Net" class="headerlink" title="Deep Net"></a>Deep Net</h2><p>Xv(150维), Xnv(380维)输入，layer1 将 Xnv 转换到1024维并连接在 Xv 后面:</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221133204.png" class="" title="layer1"> <p>后面是两层深度层，结果为一个256维向量:</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221133319.png" class="" title="layer23"><p>以上是深度网络(deep net)的嵌入结果。</p><h2 id="Cross-Net"><a href="#Cross-Net" class="headerlink" title="Cross Net"></a>Cross Net</h2><p>交叉网络(cross net)处理非视觉特征:</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221133645.png" class="" title="cross net layer"><p>z0 是一开始的 Xnv，其余均为 cross net 的参数。</p><h2 id="Sigmoid-Combine"><a href="#Sigmoid-Combine" class="headerlink" title="Sigmoid Combine"></a>Sigmoid Combine</h2><p>最后，用 sigmoid 把两方面网络的输出整合起来:</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221133823.png" class="" title="sigmoid conbine"><h1 id="Non-visual-Feature-Embedding"><a href="#Non-visual-Feature-Embedding" class="headerlink" title="Non-visual Feature Embedding"></a>Non-visual Feature Embedding</h1><p>非视觉特征的嵌入，本文采用了一种左乘一个特别的嵌入字典的方式，压缩原本非常稀疏的 One-hot 向量。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221194153.png" class="" title="Non-visual Feature Embedding"><h1 id="Category-Specific-CNN"><a href="#Category-Specific-CNN" class="headerlink" title="Category-Specific CNN"></a>Category-Specific CNN</h1><p>Category-Specific CNN, that embeds an ad image m, together with the ad category k ∈ K, to the visual feature Xv.<br>这句话说明了 CSCNN 的核心，将图片及类别一起嵌入(early fusion)。文中还提到，CSCNN 可以放到任何网络的任何一个卷积层中，这提供了很好的兼容性，具体 CSCNN 的结构，下面一一展开。</p><h2 id="Framework-on-A-Single-Convolutional-Layer"><a href="#Framework-on-A-Single-Convolutional-Layer" class="headerlink" title="Framework on A Single Convolutional Layer"></a>Framework on A Single Convolutional Layer</h2><p>单一卷积层的框架，先放上文中展示的一层卷积层的示意图。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221141056.png" class="" title="A Single Convolutional Layer"><h3 id="Channel-wise-attention"><a href="#Channel-wise-attention" class="headerlink" title="Channel-wise attention"></a>Channel-wise attention</h3><p>对于一种类别 k 和通道 C，卷积层 l，CSCNN 会学习一个 Akc(l省略) 来表示类别信息对通道注意力的影响。</p><p>对于一个(中间的)特征图 F，CSCNN 首先会学习一个包含通道信息和类别信息的 channel attention map 通道注意力特征图 Mc，然后 Mc 会和 F 进行元素乘，获得精炼特征图 F1。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221141753.png" class="" title="channel attention refine"><h4 id="Channel-wise-attention-tells-what-to-focus-on"><a href="#Channel-wise-attention-tells-what-to-focus-on" class="headerlink" title="Channel-wise attention tells what to focus on"></a>Channel-wise attention tells what to focus on</h4><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221143226.png" class="" title="channel attention"><p>为了获得空间信息，使用最大和平均池化对特征图 F 进行压缩，然后与类别先验知识向量 Akc 连接，传入共享的两层 MLP，维数从 1+1+(C+C1) 降到 1+1+C，最后通过元素和进行合并。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221153805.png" class=""><h3 id="Spatial-wise-attention"><a href="#Spatial-wise-attention" class="headerlink" title="Spatial-wise attention"></a>Spatial-wise attention</h3><p>和 Akc 类似，CSCNN 会学习一个张量 Aks，表示类别信息对空间注意力的影响。</p><p>对于精炼后的 F1，CSCNN 使用包含空间信息和类别信息的 spatial attention map 空间注意力特征图 Ms，与 F1 进行元素乘，获得精炼特征图 F2。F2 被投放到下一层作为 F 或者作为输出。</p><h4 id="Spatial-wise-attention-tells-where-to-focus-on"><a href="#Spatial-wise-attention-tells-where-to-focus-on" class="headerlink" title="Spatial-wise attention tells where to focus on"></a>Spatial-wise attention tells where to focus on</h4><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221154148.png" class="" title="spatial attention"><p>受到 CBAM 启发，CSCNN 首先沿通道维度进行平均和最大池化来汇总特征图 F 的通道信息，然后和 Aks 连接形成一个 H×W×3 的特征图，传入 7×7 的卷积过滤器。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221154640.png" class=""><h1 id="System-Deployment"><a href="#System-Deployment" class="headerlink" title="System Deployment"></a>System Deployment</h1><p>We deploy CSCNN for the search advertising system of JD.com, the largest B2C e-commerce company in China, serving the main traffic of hundreds of millions of active users.</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221154855.png" class="" title="The architecture of the online model system"><h2 id="Offline-training"><a href="#Offline-training" class="headerlink" title="Offline training"></a>Offline training</h2><p>CSCNN 与整个 CTR 系统一起，在 32 天百亿规模的真实生产数据集上训练。其中 CNN 是训练中关键计算瓶颈。以 ResNet18 网络为例，输入图片 224×224，一台有 4 个 P40GPU 的单机每天只能训练 1.77 亿张图片。意味着只考虑 CSCNN 和分布式线性加速，也需要 22640 个 GPU 才能在一天内完成百亿张图片训练。因此采用了采样策略，一个 batch 中最多收集 25 张相同特征的广告，一张图片嵌入只进行一次，并在这批图片中传播多个特征。现在 28 张 P40GPU，也能在一天内完成训练。</p><h2 id="Offline-inferring"><a href="#Offline-inferring" class="headerlink" title="Offline inferring"></a>Offline inferring</h2><p>图像和类别标签被送入 CSCNN 来推动视觉特征，制作一个 LookupTable 载入在内存中。再来一个相同的 广告ID，同一张图片，直接在LookupTable 中查找对应的视觉特征。经过降维和频率控制，一个 20GB 的 LookupTable 可以覆盖第二天 90% 的视觉特征需求。</p><h2 id="Online-serving"><a href="#Online-serving" class="headerlink" title="Online serving"></a>Online serving</h2><p>收到请求会直接从 LookupTable 查找视觉特征，返回 CTR 预测。在吞吐量 3 倍的高峰期，每秒百万条数据下，CPU 的延迟也低于 20ms。</p><h1 id="Experiment-Results"><a href="#Experiment-Results" class="headerlink" title="Experiment Results"></a>Experiment Results</h1><p>We exam the effectiveness of both our proposed visual modeling module CSCNN and the whole CTR prediction system.<br>实验主要可以分为两部分：</p><ol><li>消融实验 Ablation Study. 将 CSCNN 放入到轻量级 CNN 和小型 CTR 预测实验中，使用公开数据集保障实验的可重复性；</li><li>测试了 CTR 预测系统由于视觉模型改进得到的性能提升，包括离线实验和在线A/B对照实验。</li></ol><h2 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h2><p>Aim at “lightest” model to eliminate the “huge system” effect.<br>所以实验的目标放在了 VBPR 一种矩阵分解框架，轻量,但是和主流模型有着接近的性能。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221160612.png" class="" title="VBPR"><p> Φ 使用了 CNN-F 作为基础的 CNN，卷积2-卷积5接入了 CSCNN。</p><h2 id="Evaluation-Study"><a href="#Evaluation-Study" class="headerlink" title="Evaluation Study"></a>Evaluation Study</h2><p>简而言之，使用的是 AUC，AUC 表示使用方法后，随机预测准确相对于随机预测不准确的比例，介于(0.5, 1)之间。越接近0.5，代表预测准和不准比例差不多，随便猜猜，越接近1，方法越有效。<br>在推荐系统领域，AUC 应用得非常普遍。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221161242.png" class="" title="AUC"><p>离线实验的 AUC 很能反应在线系统的表现，对于京东 JD.com 来说，1‰ 的 AUC 增长意味着六百万美元的广告收入。</p><h2 id="Comparison-with-State-of-the-arts"><a href="#Comparison-with-State-of-the-arts" class="headerlink" title="Comparison with State-of-the-arts"></a>Comparison with State-of-the-arts</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221161825.png" class="" title="Comparison with State-of-the-arts"><p><strong>BPR-MF</strong>: The Bayesian Personalized Ranking (BPR) , No visual features. Only includes the first 4 terms in Eq(12).<br><strong>BPR-MF</strong>: 最简单的 BPR<br><strong>VBPR</strong>: BPR + visual. The visual features are extracted from pre-trained and fixed CNN [8].<br><strong>VBPR</strong>: 最简单的 BPR +视觉<br><strong>DVBPR</strong>: The visual feature extractor CNN is trained end-to-end together with the whole CTR prediction model [12].<br><strong>DVBPR</strong>: CNN-CTR 模型端到端训练<br><strong>DVBPR-C</strong>: DVBPR + category. The Category information is late fused into MF by sharing γa among items from the<br>same category.<br><strong>DVBPR-C</strong>: DVBPR +类别，类别信息后融合 late fusion<br><strong>Sherlock</strong>: DVBPR + category. Category is used in the linear transform after the visual feature extractor [7].<br><strong>Sherlock</strong>: DVBPR +类别，类别信息用于视觉提取后的线性变换层面<br><strong>DeepStyle</strong>: Category embedding is subtracted from the visual feature to obtain style information [14].<br><strong>DeepStyle</strong>: 类别嵌入从视觉特征中减去<br><strong>SCA</strong>: This algorithm was originally designed for image captioning [3] where features of captioning were used in visual attention. To make it a strong baseline in CTR prediction, we slight modify this algorithm by replacing the captioning features to category embedding, so that the category information is early fused into CNN.<br><strong>SCA</strong>: 最初设计面向图像截取，截取特征用在视觉注意力上，本实验中改变用于类别嵌入</p><h2 id="Adaptation-to-Various-Attentions"><a href="#Adaptation-to-Various-Attentions" class="headerlink" title="Adaptation to Various Attentions"></a>Adaptation to Various Attentions</h2><p>CSCNN 核心要点在于使用类别先验知识，指导注意力机制。这里实验采用了三种主流的注意力机制结构进行测试: SE、CBAM-Channel、CBAM-All</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221165336.png" class="" title="Adaptation to Various Attentions"><h2 id="Adaptability-to-Various-Network-Backbones-amp-Effects-of-Hyper-Parameters"><a href="#Adaptability-to-Various-Network-Backbones-amp-Effects-of-Hyper-Parameters" class="headerlink" title="Adaptability to Various Network Backbones &amp; Effects of Hyper-Parameters"></a>Adaptability to Various Network Backbones &amp; Effects of Hyper-Parameters</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221205310.png" class="" title="Adaptability to Different Backbones"><p>观测了 CBAM、CSCNN，以及不加注意力机制(作为基准)的时候，CNN-F 和 Inception V1 模型产生的改变。</p><p>CSCNN 可以将 CNN 下一层输入的特征图 F 替换成 精炼特征图 F2，因此可以在主流网络中用 CSCNN 替换 CNN，这里用对 Inception V1的研究展示一下，替换到怎么样的程度最好。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221170358.png" class="" title="Effects of Hyper-Parameters"><p>图左 C1 表示通道注意力的先验知识 Akc 的大小<br>图中 H1=W1 表示空间注意力的先验知识 Aks 的大小<br>图右 L 表示 CNN 最后几层卷积层替换成了 CSCNN</p><h2 id="Experiments-On-Real-Production-Dataset-amp-Online-A-B-Testing"><a href="#Experiments-On-Real-Production-Dataset-amp-Online-A-B-Testing" class="headerlink" title="Experiments On Real Production Dataset &amp; Online A/B Testing"></a>Experiments On Real Production Dataset &amp; Online A/B Testing</h2><p>真实生产数据集是从 JD.com 的广告互动日志中抽取的，使用前 32 天的日志训练，第 33 天开始抽取 50w 次投放进行测试。<br>真实生产数据集的部分统计信息如表：</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221171331.png" class="" title="Real Production Dataset Statistics"><p>在下表中展示的实验结果，验证了本文内容的有效性:</p><ol><li>固定 CNN 增益代表视觉特征 visual feature 的重要性</li><li>微调 finetune 收益验证了 端到端训练 end-to-end train 的重要性</li><li>CBAM 收益验证了注意力机制的重要性</li><li>CSCNN 收益验证了提取将类别先验知识纳入卷积层，使得通道和空间的注意力机制学习更有效<img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221171725.png" class="" title="Experiments on Real Production Dataset">在线实验 A/B test，和之前京东的 DCN 在线模式对比，CSCNN 贡献了 3.22% 的 CTR(点击率)，2.46%的eCPM(每千次投放收益)，并减少了 0.62%(点击成本)。对于京东来说，是不小的收益。</li></ol><h2 id="附录-A"><a href="#附录-A" class="headerlink" title="附录 A"></a>附录 A</h2><p>附录 A 主要描述了，原实验用的是 <strong>点损失 Point-wise loss</strong>，而在一些同样应用于 benchmark Amazon数据集的其他研究中，也有使用 <strong>成对损失 Pair-wise loss</strong> 的存在，因此也做了这样的实验，验证了原结论不变。结果如下：</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221172810.png" class="" title="AUC under Pairwise Loss"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221172845.png" class="" title="AUC under Pairwise Loss"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221172930.png" class="" title="AUC under Pairwise Loss"><h2 id="附录-B"><a href="#附录-B" class="headerlink" title="附录 B"></a>附录 B</h2><p>附录 B 主要对生产数据集进行了统计描述，真实数据特征都非常的稀疏，遵循长尾分布，80% 的数据在训练集中出现不到 6 次。研究表明，在数据非常稀疏的情况下，提供视觉特征对建模预测的贡献是很大的。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221173528.png" class="" width="560" height="700" title="Feature statistics from the search advertising system of JD.com from 20200106 to 20200206 L"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221173603.png" class="" width="560" height="700" title="Feature statistics from the search advertising system of JD.com from 20200106 to 20200206 M"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221173931.png" class="" width="560" height="700" title="Feature statistics from the search advertising system of JD.com from 20200106 to 20200206 R">]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>推荐系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>推荐系统</tag>
      
      <tag>CNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker 基础操作知识</title>
    <link href="/2022/02/20/docker-knowledge/"/>
    <url>/2022/02/20/docker-knowledge/</url>
    
    <content type="html"><![CDATA[<p>暂时还没有规划完成。</p>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python 环境管理</title>
    <link href="/2022/02/20/python-env-manage/"/>
    <url>/2022/02/20/python-env-manage/</url>
    
    <content type="html"><![CDATA[<p>やあ！　みんな！<br>时隔一个月重新拾起了这篇没有写的内容，感谢朋友的 push。<br>实验环境管理，同论文排版、文献管理一样作为研究生的基本功三板斧之一，一定要修炼好。我主要在这里写一下，我的实验环境配置方案。本篇同 <a href="/2022/02/20/docker-knowledge/" title="Docker 基础操作知识">Docker 基础操作知识</a> 一起，都会涉及到和环境有关的知识。</p><p>注：这会是一篇很长的内容，并且会在若干天内更新完。</p><p>注2：如果你是想搞一个简单的环境，建议就看一看 conda 环境，稍微了解 Docker、SSH 内容</p><h1 id="我的世界"><a href="#我的世界" class="headerlink" title="我的世界"></a>我的世界</h1><p>我的环境比较简单，在 Management Science 学习，主要写一些爬虫和机器学习实验，工具如下：</p><table><thead><tr><th>工具</th><th>作用</th></tr></thead><tbody><tr><td>Github</td><td>代码仓库，偶尔也用 Gitee，这个 BLOG 就使用了 Github Pages 服务</td></tr><tr><td>Git</td><td>代码版本管理工具</td></tr><tr><td>v2???</td><td>一种 V 开头的特殊软件，攀爬?时非常实用</td></tr><tr><td>Anaconda</td><td>实际上用的是 conda，一种很好用的 py 环境管理工具</td></tr><tr><td>WindowsTerminal</td><td>比较好看的终端🤣</td></tr><tr><td>GitBash</td><td>我的平台是 Windows，为了方便用了 Git 带的 Bash，配合 WindowsTerminal</td></tr><tr><td>Pycharm Pro</td><td>Student License 的 Pycharm，<a href="https://www.jetbrains.com/zh-cn/community/education/#students" target="blank"><img src="https://img.shields.io/badge/Thanks-Jetbrains-green"></img></a></td></tr><tr><td>JupyterLab</td><td>一种交互式的 Web Python 实验环境</td></tr><tr><td>MobaXterm</td><td>SSH 工具，连接服务器环境，同样 Xshell 我也有在使用，二者都提供了免费个人许可证</td></tr><tr><td>Docker Desktop</td><td>WSL 后端的 Docker Desktop，制作服务器用的环境时用到</td></tr><tr><td>Visual Studio Code</td><td>我没装什么插件，当作一个朴实的代码/文本编辑器在用</td></tr></tbody></table><p>此外，我还有一张 GTX1660s 和一张 Tesla v100(Docker) 可以用，这里建议有一张 Nvidia 的小显卡，比如 MX450 这种的，以支持 cuda 来试一试一些小模型，同样也是要学习怎么部署 cuda</p><h1 id="using-Bing-com-instead-of-Baidu"><a href="#using-Bing-com-instead-of-Baidu" class="headerlink" title="using Bing.com instead of Baidu"></a>using Bing.com instead of Baidu</h1><h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><h1 id="v2"><a href="#v2" class="headerlink" title="v2???"></a>v2???</h1><h1 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h1><h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><h2 id="Mirror-镜像站"><a href="#Mirror-镜像站" class="headerlink" title="Mirror 镜像站"></a>Mirror 镜像站</h2><h1 id="Reverse-Server-Port"><a href="#Reverse-Server-Port" class="headerlink" title="Reverse Server Port"></a>Reverse Server Port</h1><h1 id="SSH-into-Server-Environment"><a href="#SSH-into-Server-Environment" class="headerlink" title="SSH into Server Environment"></a>SSH into Server Environment</h1><h1 id="Pycharm-SSH"><a href="#Pycharm-SSH" class="headerlink" title="Pycharm + SSH"></a>Pycharm + SSH</h1><h1 id="Reverse-JupyterLab-Port"><a href="#Reverse-JupyterLab-Port" class="headerlink" title="Reverse JupyterLab Port"></a>Reverse JupyterLab Port</h1><h1 id="Transfer-file-by-SSH"><a href="#Transfer-file-by-SSH" class="headerlink" title="Transfer file by SSH"></a>Transfer file by SSH</h1><h1 id="Install-Docker-on-Windows"><a href="#Install-Docker-on-Windows" class="headerlink" title="Install Docker on Windows"></a>Install Docker on Windows</h1><h1 id="Make-Push-a-container-to-our-Server"><a href="#Make-Push-a-container-to-our-Server" class="headerlink" title="Make + Push a container to our Server"></a>Make + Push a container to our Server</h1>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用 Frp 内网穿透 RDP 远程桌面</title>
    <link href="/2022/02/20/rdp-with-frp/"/>
    <url>/2022/02/20/rdp-with-frp/</url>
    
    <content type="html"><![CDATA[<p>这是回 DUT 之后的第一篇日志，尽管早已经规划好了，但是这几天在忙家里的事情就没有写。RDP(Remote Desktop Protocol)是一项应用很广的远程桌面协议，最常见的环境就是 Windows 的远程桌面了。RDP 有传输视音讯、本地显卡渲染、传输剪贴板等等，是我最主要的远程桌面工具。</p><p>Frp 是大家熟知的一款几乎跨所有平台的内网穿透工具，也是我远程桌面的核心一环。</p><h1 id="RDP"><a href="#RDP" class="headerlink" title="RDP"></a>RDP</h1><p>正如之前介绍过的，RDP 协议是 Windows 平台最常用的，也是我认为最方便的远程桌面工具。RDP 协议默认已经安装于常用的 Windows 系统，包括家庭版、专业版以及 Server 版等等，这里我简单的用 Windows10 家庭版/专业版介绍一下:</p><h2 id="开启方式"><a href="#开启方式" class="headerlink" title="开启方式"></a>开启方式</h2><p>打开 Windows Setting APP，在 Windows10 的设置中，利用搜索 “远程桌面”，很容易找到远程桌面的设置选项:</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228103921.png" class="" title="远程桌面设置"><p>将“启用远程桌面”开关启动，简单地提示配置账户信息，被控制机的 RDP 监听就启动了。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228103959.png" class="" title="开启远程桌面"><p>完成。</p><p>还有一件重要的事情，记录下这台电脑的 IP 地址。<br>点击右下角的网络图标，进入以太网/WLAN 设置，点击你拥有的网络，找到“属性”一栏</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/2022-02-28104538.png" class="" title="网络属性"><p>你需要记录下当前设备的 IPv4 地址(IPv6 也可以记录使用，但是不会作为本文的演示)</p><table><thead><tr><th>项目</th><th>内容</th></tr></thead><tbody><tr><td>IPv4</td><td>10.7.*.*</td></tr></tbody></table><h2 id="连接方式"><a href="#连接方式" class="headerlink" title="连接方式"></a>连接方式</h2><p>连接使用的机器，通常是同网络(同一校园网，同一局域网等，关于网络是不是可达，简单地 PING 被控 IPv4 大致可以判断)</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/2022-02-28105432.png" class="" title="PING"><p>我们在控制机(通常会是你的便携式笔记本、其他终端等)上，从开始菜单搜索“远程桌面”，即可打开“远程桌面连接” APP</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228105813.png" class="" title="远程桌面连接"><p>下面是将会需要我们填写的参数:</p><table><thead><tr><th>项目</th><th>内容</th></tr></thead><tbody><tr><td>计算机</td><td>被控机 IPv4</td></tr><tr><td>用户名</td><td>用户名</td></tr><tr><td>密码</td><td>(当你点击连接后会要求)</td></tr></tbody></table><p>注: 当用户使用的是 Windows 本地账户时，用户名和密码即本地账户的用户名和密码；当用户使用 Microsoft 账户时，用户名和密码可以使用 MS 账户邮箱和 MS 账户密码。</p><p>需要将控制机的硬件，挂载到被控机使用时，比如在两机之间交换文件，可以检视一下“本地资源-本地设备和资源”。</p><p>That’s all, happy remoting !</p><h1 id="RDP-across-Internet-use-Frp"><a href="#RDP-across-Internet-use-Frp" class="headerlink" title="RDP across Internet(use Frp)"></a>RDP across Internet(use Frp)</h1><p>在上面我们介绍的架构中，RDP 仅仅能在局域网中工作，然而有时候外出/假期，我们必须依赖 Internet 进行 RDP。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228111605.png" class="" title="局域网 RDP"><p>如果你的被控机拥有被称作“公网IP”的 IPv4 地址，比如云服务商购买的 vps，那么问题解决，直接连接即可。但是通常，我们需要一个中转服务器进行 RDP 数据的转发。</p><blockquote><p>将没有公网 IP 的服务，通过 Internet 连接、公网 IP 服务器、流量穿透软件，映射到公网服务器上，使得用户在访问公网服务器对应的服务时，流量能够转发到被映射的内网服务中，达到缺乏公网 IP 也能访问服务的效果</p><footer><strong>内网穿透</strong></footer></blockquote><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228113120.png" class="" title="内网穿透 RDP"><p>如示意图展示，我们通过部署内网穿透服务后，在被控机上的 RDP 服务“好像”运行在中转机上一样，我们只要访问拥有公网 IP 的中转机，流量即可抵达被控机，而内网穿透的流量发送细节由内网穿透软件完成，不需要用户关心。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228135323.png" class="" title="Frp穿透"><p>下面，我会部署一对 Frps 和 Frpc 来将我本地的 RDP 映射到位于腾讯云的轻量服务器上。一个 Frps 可以接受来自多个 Frpc 的穿透请求。</p><h2 id="Frps"><a href="#Frps" class="headerlink" title="Frps"></a>Frps</h2><p>这里是 Frp 的官方开源地址，<a href="https://github.com/fatedier/frp" title="" target="">github.com&#x2F;fatedier&#x2F;frp</a><br>下载 Release 中和服务器系统对应的执行文件压缩包，解压并保留 frps 执行文件。</p><p>撰写(也可以编辑上面压缩包带的 frps_full.ini 文件)一个 config.ini 配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">[common]<br>bind_addr = 0.0.0.0          <span class="hljs-comment"># 监听地址，0.0.0.0 即可</span><br>bind_port = 7000             <span class="hljs-comment"># 监听端口，默认 7000，可以更改</span><br>token = something_complex    <span class="hljs-comment"># token，拥有相同 token 的 Frpc 才能连接到这个 Frps</span><br></code></pre></td></tr></table></figure><p>配置文件非常简单，之后在这个目录，启动即可发起监听。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./frps -c config.ini<br></code></pre></td></tr></table></figure><p>需要释放 7000 端口防火墙，进阶用户如果需要配置 systemd 服务，可以自行查看 systemd 文件夹的内容。建议了解并配置一下。</p><h2 id="Frpc"><a href="#Frpc" class="headerlink" title="Frpc"></a>Frpc</h2><p>这里是 Frp 的官方开源地址，<a href="https://github.com/fatedier/frp" title="" target="">github.com&#x2F;fatedier&#x2F;frp</a><br>下载 Release 中和被控机系统对应的执行文件压缩包，解压并保留 frpc 执行文件(frpc.exe)。</p><p>撰写(也可以编辑上面压缩包带的 frpc_full.ini 文件)一个 config.ini 配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">[common]<br>server_addr = 81.70.*.*      <span class="hljs-comment"># 中转服务器的公网 IPv4 地址</span><br>server_port = 7000           <span class="hljs-comment"># 和 frps 的 bind_port 一致</span><br>token = something_complex    <span class="hljs-comment"># 和 frps 的 token 一致</span><br><br>[RDP]                        <span class="hljs-comment"># RDP 的配置信息</span><br><span class="hljs-built_in">type</span> = tcp<br>local_ip = 127.0.0.1<br>local_port = 3389<br>remote_port = 3389<br><br>[RDP_UDP]                    <span class="hljs-comment"># 启动 UDP 获得更好的远程桌面体验</span><br><span class="hljs-built_in">type</span> = udp<br>local_ip = 127.0.0.1<br>local_port = 3389<br>remote_port = 3389<br></code></pre></td></tr></table></figure><p>撰写完毕之后就可以启动，利用 cmd/powershell 进入执行文件目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./frpc.exe -c config.ini<br></code></pre></td></tr></table></figure><p>启动后能看到连接服务器成功的日志，代表穿透成功。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228142225.png" class="" title="成功 log"><p>连接时候，目标 IP 地址就要换成中转机器的地址。</p><table><thead><tr><th>项目</th><th>内容</th></tr></thead><tbody><tr><td>计算机</td><td>被控机 IPv4</td></tr><tr><td><em>更改为</em></td><td></td></tr><tr><td>计算机</td><td>中转机 IPv4</td></tr><tr><td>用户名</td><td>用户名</td></tr><tr><td>密码</td><td>(当你点击连接后会要求)</td></tr></tbody></table><h2 id="Frpc-installed-as-Windows-Service"><a href="#Frpc-installed-as-Windows-Service" class="headerlink" title="Frpc installed as Windows Service"></a>Frpc installed as Windows Service</h2><p>使用 Frpc 时，在 Windows 需要打开一个命令行窗口，既带来了界面上的不美观，也容易误关导致远程 RDP 失败，因此我们的目标是将 frpc 安装至 Windows 服务，使其位于后台运行。</p><h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><p>我们需要依赖一个叫做 nssm 的软件。<a href="https://nssm.cc/" title="" target="">nssm.exe</a><br>软件下载后只有一个 nssm.exe 小巧但是够用。将 nssm.exe 和 frpc.exe 放在一起。</p><p>利用管理员权限的 cmd/powershell，执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./nssm.exe install<br></code></pre></td></tr></table></figure><p>弹出 nssm 的软件，填写恰当的参数后，即可将 frpc 安装至服务中。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228144911.png" class="" title="nssm"><table><thead><tr><th>项目</th><th>内容</th></tr></thead><tbody><tr><td>Application</td><td></td></tr><tr><td>Path</td><td>frpc.exe 所在完整路径</td></tr><tr><td>Startup directory</td><td>frpc.exe 所在目录</td></tr><tr><td>Arguments</td><td>-c config.ini 所在目录</td></tr><tr><td>Service name</td><td>起个服务名称，如 frpc</td></tr><tr><td>Details</td><td></td></tr><tr><td>Display name</td><td>建议和 Service name 一样即可</td></tr><tr><td>Description</td><td>写点注释</td></tr><tr><td>Startup type</td><td>保持 Automatic 自动启动即可</td></tr></tbody></table><p>点击 Install service 即安装完毕，重启或进入“任务管理器—服务—打开服务”，找到你刚才安装的服务启动即可。</p><p>不论如何，都建议去“任务管理器—服务—打开服务”看一眼服务是否正常启动。</p><h3 id="Uninstall"><a href="#Uninstall" class="headerlink" title="Uninstall"></a>Uninstall</h3><p>和 Install 步骤基本一致<br>利用管理员权限的 cmd/powershell，执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./nssm.exe remove<br></code></pre></td></tr></table></figure><p>弹出 nssm 的软件，填写需要卸载的<strong>服务名称</strong>即可。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228145820.png" class="" title="remove frpc 服务"><p><strong>服务名称</strong> 可以在“任务管理器—服务—打开服务”，该项服务的属性中查询得到。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220228145549.png" class="" title="frpc 服务名称"><p>注意，服务中默认显示的是“展示名称”，和属性中的“服务名称”可能不一致。</p><p>卸载完毕后重启，由 nssm 安装的服务便被删除了。</p><p>最后，推荐由 natfrp 提供的 <a href="https://www.natfrp.com/?page=register" title="" target="">SakuraFrp</a> 服务，免费提供公网 Frps 和映射软件，其免费额度对于普通的 RDP 用户完全够用，两条隧道额度刚好满足 RDP + RDP_UDP。<br>作为白嫖党的我希望你能成为我们的一员(够了不要再说了)。</p>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Frp</tag>
      
      <tag>RDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker 服务器的一些介绍资料</title>
    <link href="/2022/02/20/docker-server/"/>
    <url>/2022/02/20/docker-server/</url>
    
    <content type="html"><![CDATA[<p>やあ　みんな！</p><p>很高兴我前不久接管了一台服务器，Xeon Silver 4216，64G，2T Raid0，带有公网访问，没有公网IP。以前接手的都是自己买的 vps 小鸡，因此突然收获了这样一台性能不错的服务器也是很开心啦。</p><p>装好基础的系统，配置好 SSH 之后在工位思考，归我管控但毕竟是团队的资源，因此要想办法提高资源利用啦。考虑过 KVM，也考虑过 lxc，但是一想到还是需要自己编排调度，又或需要自己维护就很头疼啦。</p><p>再考虑，装上开源云盘做团队的内网云存储，但调查了一下，人气实在是不高，便捷程度也遭到了怀疑。<br>后来经过一番调研，终于决定和 AiStation 一样，用作 Docker Server，让大家差不多当虚拟环境使用啦。</p><p>PS: 以下涉及到的 Url 地址都是在 DUT 的校内网地址。</p><h1 id="Portainer"><a href="#Portainer" class="headerlink" title="Portainer"></a>Portainer</h1><ul><li><strong>Portainer 用户登录地址</strong>:<br><a href="https://10.8.130.137:9443/">https://10.8.130.137:9443/</a></li><li><strong>Portainer 用户名</strong>:<br>姓名拼音，如【小林绿子】-【xiaolinlvzi】</li><li><strong>Portainer 用户默认密码</strong>:<br>1</li></ul><p>注意: 请务必在第一次登录时更改密码<br>注意: 不要将 Container 当作特别重要内容的存储节点</p><h2 id="首页"><a href="#首页" class="headerlink" title="首页"></a>首页</h2><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222131512.png" class="" title="portainer.io 首页"><p>首页能看到的环境目前只有一个，即 local 本机环境，用户拥有创建更改容器权限的位置目前也是在这个 local 环境，可以看到用户已经创建的 Container，目前服务器中已经有的 images 等内容，下面简单写一下创建容器的方法。</p><h2 id="创建容器-Containers"><a href="#创建容器-Containers" class="headerlink" title="创建容器 Containers"></a>创建容器 Containers</h2><p>进入 Container 选单，可以看到目前正在运行、停止中的容器，点击 Add container</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222133136.png" class="" title="Container 选单"><p>进入创建容器的选单，这里以一个最普通的 Ubuntu 容器示例:</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222134149.png" class="" title="创建container1"><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222134253.png" class="" title="创建container2"><table><thead><tr><th>选单名</th><th>解释内容</th></tr></thead><tbody><tr><td><strong>Name</strong></td><td>容器名字，自己选容易知道是干什么的就行</td></tr><tr><td><strong>Registry</strong></td><td>镜像地址，默认是 DockerHub(anonymous)，懂的用户可以进入 Advanced mode 自行选择拉取镜像的仓库</td></tr><tr><td><strong>Image</strong></td><td>填写用户/镜像名:tag，即传统 Cli 命令下 docker pull 的内容</td></tr><tr><td><strong>Always pull the image</strong></td><td>创建容器时，如果 image 已经在本机 Images 中，建议关掉此选项以节省服务器流量</td></tr><tr><td><strong>Network ports configuration</strong></td><td>很多初始容器可能不包含后面你要用到的端口，因此我建议使用 Manual network port publishing</td></tr><tr><td></td><td>【举例: 这里我们创建的 ubuntu 要用到 SSH，因此将 host:10030 -&gt; container: 22 TCP 链路配置好，映射 SSH 的 22 端口到我们的服务器 10030 端口上，或者不用的其他端口都可以】当然你的一次性容器的 Dockerfile 中有写好，也可以使用第一个选项</td></tr><tr><td></td><td>【注意：本机 10000-65535 端口开放 Docker容器 使用】</td></tr><tr><td></td><td>如果你创建的时候碰到 “portinuse”、”error code 500” 等错误，说明存在端口冲突了，请更改一下 host 端口</td></tr><tr><td><strong>Access control</strong></td><td>完全自用就选 Private，共享给大家就选 Restricted 并配置</td></tr><tr><td><strong>Advanced container settings</strong></td><td>进阶配置，当你知晓其中的功用再配置</td></tr><tr><td></td><td>【注意: Ubuntu 容器比较特殊，需要进行命令行交互，请勾选 Advanced container settings – Command &amp; logging – Console – Interactive &amp; TTY(-i -t)】</td></tr></tbody></table><p>好啦，这样一来容器就已经部署了，由于非常轻量一下子就运行起来啦！<br>我们点击容器名进去可以查看到容器的详细信息 Container Details</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222140432.png" class="" title="创建container3"><p>这里呢，点击 console 按钮，进入连接终端的界面，进入容器内部执行命令啦！<br>我们以默认的 /bin/bash 命令，Connect 到容器内部</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222140724.png" class="" title="连接容器 Console"><p>之后，建议参考下面第一个 <strong>示例：创建一个可以 SSH 的 Ubuntu 容器</strong></p><a href="https://yunchaozheng.github.io/2022/02/20/docker-server/#%E7%A4%BA%E4%BE%8B%EF%BC%9A%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5-SSH-%E7%9A%84-Ubuntu-%E5%AE%B9%E5%99%A8" title="" target="">示例：创建一个可以 SSH 的 Ubuntu 容器</a><h1 id="AiStation-异同"><a href="#AiStation-异同" class="headerlink" title="AiStation 异同"></a>AiStation 异同</h1><p>创建这个 Docker 服务器的时候我还蛮在思考的，毕竟已经有 AiStation 这个级别的计算平台作为 Docker 服务器了，但是后来我想了想团队的 Docker 服务器还是蛮有用的，至于为什么我就在这里解释一下吧。</p><h2 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h2><p>Portainer.io 和 AiStation 都是基于 Docker 的服务器，都能够很方便地<br><strong>创建容器</strong>、<strong>管理容器</strong>、<strong>管理镜像</strong>、<strong>映射端口</strong>、<strong>发布镜像包</strong> 等等功能</p><h2 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h2><table><thead><tr><th></th><th>Portainer.io</th><th>AiStation</th></tr></thead><tbody><tr><td>定位</td><td>常备 Docker 服务器，为团队个人提供高性能容器、制作、发布，或者作为常备服务运行</td><td>科学计算、深度学习平台，学院公用平台，资源有限</td></tr><tr><td>GPU support</td><td>✘</td><td>✓</td></tr><tr><td>Internet support</td><td>✓</td><td>✘</td></tr><tr><td>资源量</td><td>团队共享，64C64G</td><td>学院共享，32CNaNG</td></tr><tr><td>容器持久运行</td><td>✓</td><td>✘</td></tr><tr><td>端口映射</td><td>✓</td><td>✓</td></tr><tr><td>容器数量</td><td>NaN</td><td>2</td></tr><tr><td>自定义容器</td><td>DockerHub pull 直接创建</td><td>打包image，上传创建</td></tr><tr><td>Stack 支持</td><td>✓</td><td>✘</td></tr></tbody></table><p>作为 Docker 服务器，我们的服务器拥有一定的 CPU 算力，因此 CPU 密集型任务，比如聚类计算等，除了 AiStation ，现在我们有了第二选择，当然比较重的计算任务我还是更推荐装载到 AiStation 上进行。</p><h1 id="连接方式"><a href="#连接方式" class="headerlink" title="连接方式"></a>连接方式</h1><h1 id="示例：创建一个可以-SSH-的-Ubuntu-容器"><a href="#示例：创建一个可以-SSH-的-Ubuntu-容器" class="headerlink" title="示例：创建一个可以 SSH 的 Ubuntu 容器"></a>示例：创建一个可以 SSH 的 Ubuntu 容器</h1><p>但是仅仅能用 Console 不够满足吧，配置好 SSH 能够通过远程使用，并通过 SFTP 等手段交互文件，才是我们真正想要做的目的吧。这里为了简单起见，我就先引用了之前胡言乱语的文章好了。</p><a href="/2022/02/20/sshable-ubuntu-docker/" title="为 Docker 的 ubuntu 容器启用 SSH">为 Docker 的 ubuntu 容器启用 SSH</a><h2 id="外部连接-Container"><a href="#外部连接-Container" class="headerlink" title="外部连接 Container"></a>外部连接 Container</h2><p>这里说的外部，就是指的是你的电脑哇！因为你想一下，毕竟创建什么的，也不是把你的键盘真的插到机房的机架硬体中呢。我们刚刚示例中已经提到了，【host:10030 -&gt; container:22】端口映射已经设置好了。那么我们需要的内容都准备好了。</p><p><strong>原料</strong>: Ubuntu 的 container(with ssh)、自己的电脑、SSH 软件(xshell、putty、mobaxterm 等)、程序员(初心者)一枚、有点啰嗦的教程文章<br><strong>目标菜品</strong>: 在自己电脑 SSH 到 container<br><strong>支援信息</strong>:</p><table><thead><tr><th>项目</th><th>内容</th><th>注释</th></tr></thead><tbody><tr><td>address</td><td>10.8.130.137</td><td>主机IP</td></tr><tr><td>port</td><td>10030</td><td>设定host端口</td></tr><tr><td>username</td><td>root</td><td>用户名</td></tr><tr><td>password</td><td>***</td><td>密码</td></tr></tbody></table><p>这里我是用 xshell 作示例啦，但是自己用方便的软件就可以了。<br>主界面主要填名称、主机和端口号就可以了</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222145245.png" class="" width="429" height="414" title="xshell1"><p>点击用户身份验证，填好用户名和密码就可以确定了。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222145343.png" class="" width="429" height="414" title="xshell2"><p>接受并保存主机密钥，就连接上啦~</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222145814.png" class="" width="429" height="268" title="xshell3"><h1 id="示例：创建一个可以-VNC-的-Linux-容器"><a href="#示例：创建一个可以-VNC-的-Linux-容器" class="headerlink" title="示例：创建一个可以 VNC 的 Linux 容器"></a>示例：创建一个可以 VNC 的 Linux 容器</h1><p>这里找了一个不错的已经配置好的 VNC-Ubuntu 镜像，提供一下。</p><a href="https://hub.docker.com/[object%20Object]ubuntu-desktop-lxde-vnc/" title="" target="">dorowu&#x2F;ubuntu-desktop-lxde-vnc</a><p>看了一下这个镜像的启动命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -p 6080:80 -p 5900:5900 -e VNC_PASSWORD=mypassword -v /dev/shm:/dev/shm dorowu/ubuntu-desktop-lxde-vnc<br></code></pre></td></tr></table></figure><p>创建 container 的信息，举个例子</p><table><thead><tr><th>选单名</th><th>解释内容</th></tr></thead><tbody><tr><td><strong>Name</strong></td><td>vnc-ubuntu</td></tr><tr><td><strong>Registry</strong></td><td>DockerHub(anonymous)</td></tr><tr><td><strong>Image</strong></td><td>dorowu/ubuntu-desktop-lxde-vnc</td></tr><tr><td><strong>Always pull the image</strong></td><td>No</td></tr><tr><td><strong>Network ports configuration</strong></td><td>host:16080-&gt;container:80;  host:15900-&gt;container:5900</td></tr><tr><td><strong>Advanced container settings-Env</strong></td><td>VNC_PASSWORD=mypassword</td></tr><tr><td><strong>Advanced container settings-Volumes</strong></td><td>/dev/shm –bind–&gt; /dev/shm</td></tr></tbody></table><p>这里用 mobaxterm 来做示例好了。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222163047.png" class="" title="mobaxterm vnc1"><p>填写正确的信息后，连接会跳出需要密码的提示框，密码即刚刚的 <strong>VNC_PASSWORD</strong> 值。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222163353.png" class="" title="mobaxterm vnc2"><p>一个相当于虚拟机的容器就完成啦。</p><p>而通过浏览器使用 HTML5 来访问 VNC 的话，会出现 <strong>ERR_UNSAFE_PORT</strong> 错误，无法访问，据搜索解决措施可能是更换端口，或者尝试根据镜像指示，配置 ssl 应该就能解决。</p><h1 id="示例：创建一个自己用的-Draw-io-容器"><a href="#示例：创建一个自己用的-Draw-io-容器" class="headerlink" title="示例：创建一个自己用的 Draw.io 容器"></a>示例：创建一个自己用的 Draw.io 容器</h1><p>drawio 的官方镜像，提供一下。</p><a href="https://hub.docker.com/[object%20Object]drawio/" title="" target="">jgraph&#x2F;drawio</a><p>看了一下这个镜像的启动命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run -it --<span class="hljs-built_in">rm</span> --name=<span class="hljs-string">&quot;draw&quot;</span> -p 8080:8080 -p 8443:8443 jgraph/drawio<br></code></pre></td></tr></table></figure><p>创建 container 的信息，举个例子</p><table><thead><tr><th>选单名</th><th>解释内容</th></tr></thead><tbody><tr><td><strong>Name</strong></td><td>drawio</td></tr><tr><td><strong>Registry</strong></td><td>DockerHub(anonymous)</td></tr><tr><td><strong>Image</strong></td><td>jgraph/drawio</td></tr><tr><td><strong>Always pull the image</strong></td><td>No</td></tr><tr><td><strong>Network ports configuration</strong></td><td>host:18080-&gt;container:8080;  host:18443-&gt;container:8443</td></tr></tbody></table><p><strong>18443</strong> 是 ssl 端口，根据 drawio 官方指南，需要自己上传证书才能正常使用。<br>我访问了 <strong>18080</strong> 端口，成功访问了我们刚刚创建的 drawio 容器，以后就拿它来画图吧。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222164813.png" class="" title="drawio container"><h1 id="示例：为-AiStation-打包镜像"><a href="#示例：为-AiStation-打包镜像" class="headerlink" title="示例：为 AiStation 打包镜像"></a>示例：为 AiStation 打包镜像</h1><p>AiStation 上传自己镜像的办法，就是上传 image 的 tar 导出包。那么，我们需要做的事情，就是把我们的容器导出到 tar 包，命令行怎么做，可以参考另一篇文章，而 portainer.io 则可以简单点点手指进行导出。</p><a href="/2022/02/20/docker-knowledge/" title="Docker 基础操作知识">Docker 基础操作知识</a><p>直接点进 Container 的详情，找到 <strong>Create image</strong> 选单。写下你要导出的 image 的名字，注意命名的一些规范。通常是【name:tags】，名字和标签都要写。示例:<br>ubuntu:my_first<br>nginx:alpha<br>drawio:20220222_altered</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222165634.png" class="" title="create image"><p>创建好后，进入 <strong>Images</strong> 选单页，通过你命名的【name:tags】找到你的 image，点进详情进行导出，根据镜像大小，上面的操作都会花费一些时间。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222170020.png" class="" title="export image"><p>导出完毕的 tar 包，就随你处置啦。</p><p>【注意】：Image details 选单顶部的 <strong>Image tags</strong> 的上传按钮(upload)不要点!!!!!!!<br>不要随随便便把自己的 image 上传到仓库中。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222170326.png" class="" title="dont upload image"><h1 id="示例：配合-Jetbrains-通过-SSH-远程部署"><a href="#示例：配合-Jetbrains-通过-SSH-远程部署" class="headerlink" title="示例：配合 Jetbrains 通过 SSH 远程部署"></a>示例：配合 Jetbrains 通过 SSH 远程部署</h1><blockquote><p>麻烦你教我如何用 Jetbrains 通过 SSH 部署代码哦! 喵~</p><footer><strong>艾莉丝·格雷拉特</strong><cite>无职转生~到了异世界就拿出真本事~</cite></footer></blockquote><p>Jetbrains 的开发工具基本上都是一个套路，这里拿一个最简单的 case:</p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arcade">通过 Pycharm，在自己开发机上编写代码，一键 SSH 部署到 Container 中执行，通过 <span class="hljs-built_in">console</span> 等方式返回结果。<br></code></pre></td></tr></table></figure><p>其实搞明白 SSH 需要什么之后，把信息配置好就可以了，Portainer 或者 AiStation 都是一个套路，那么重复一下上面的 SSH 操作吧。</p><p><strong>原料</strong>: Ubuntu 的 container(with ssh)、自己的电脑、SSH 软件(xshell、putty、mobaxterm 等)、程序员(初心者)一枚、有点啰嗦的教程文章<br><strong>目标菜品</strong>: 在自己电脑 SSH 到 container<br><strong>支援信息</strong>:</p><table><thead><tr><th>项目</th><th>内容</th><th>注释</th></tr></thead><tbody><tr><td>address</td><td>10.8.130.137</td><td>主机IP</td></tr><tr><td>port</td><td>10030</td><td>设定host端口</td></tr><tr><td>username</td><td>root</td><td>用户名</td></tr><tr><td>password</td><td>***</td><td>密码</td></tr></tbody></table><p>这里要注意一下，就是要先在 Container 中装好 python(或者你是 Java 或者 Go 什么都是一样)，搞清楚 python 执行文件在哪里，比如像我这样子:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 <span class="hljs-comment"># 看一下有没有 python</span><br>        <span class="hljs-comment"># 当然更推荐用 update-alternatives 更新一下默认 python 的链接</span><br>whereis python3<br>        <span class="hljs-comment"># 可以看到 /usr/bin/python3 就是 python3 的执行文件</span><br>        <span class="hljs-comment"># 那一堆东西链接的 python 执行文件其实都是同一个的说</span><br>python3: /usr/bin/python3.8 /usr/bin/python3 /usr/lib/python3.8 /usr/lib/python3 /etc/python3.8 /etc/python3 /usr/local/lib/python3.8 /usr/share/python3<br></code></pre></td></tr></table></figure><p>在 Pycharm 的 File - Settings - Project: helloworld 设定<br>找到 Python Interpreter 当前用的是本地的 python 解释器的说<br>点击三个小圆点，增加一个解释器，选择 SSH Interpreter<br>按照上方信息填入就可以了哦~</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222204056.png" class="" title="Pycharm SSH1"><img class=""><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222204152.png" class="" title="Pycharm SSH2"><p>这里要填对你想要使用的 python 解释器路径哦~</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220222204320.png" class="" title="Pycharm SSH3"><h1 id="示例：创建一套-Hadoop-集群-伪"><a href="#示例：创建一套-Hadoop-集群-伪" class="headerlink" title="示例：创建一套 Hadoop 集群(伪)"></a>示例：创建一套 Hadoop 集群(伪)</h1><p>我已经累得一点都不剩了</p><h1 id="示例：创建一套-Overleaf-Community-自用版本"><a href="#示例：创建一套-Overleaf-Community-自用版本" class="headerlink" title="示例：创建一套 Overleaf Community 自用版本"></a>示例：创建一套 Overleaf Community 自用版本</h1><p>我已经累得一点都不剩了</p><h1 id="后记：吃我伯雷亚斯铁拳"><a href="#后记：吃我伯雷亚斯铁拳" class="headerlink" title="后记：吃我伯雷亚斯铁拳~"></a>后记：吃我伯雷亚斯铁拳~</h1><p>由于有 Internet 和自主创建容器的权限，拥有了计算力和网路之后，很容易让人想到干坏事的方面去。大陆地区已经全面禁止干那种坏事啦，如果还想偷偷摸摸干坏事的话，DNS 走的是学校的 DNS 会被发现，我也会毫不留情地用 Portainer Administrators 组账户和 root 账户把你 Ban 掉啦。</p><img src="https://cdn.jsdelivr.net/gh/yunchaozheng/putpicshere/imgs/20220221223435.png" class="" title="不要惹艾丽丝生气哦喵~">]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>为 Docker 的 ubuntu 容器启用 SSH</title>
    <link href="/2022/02/20/sshable-ubuntu-docker/"/>
    <url>/2022/02/20/sshable-ubuntu-docker/</url>
    
    <content type="html"><![CDATA[<p>以前在本机倒也还好，对于 Docker 中的 ubuntu 容器什么的，使用 Docker Desktop 的终端窗口连接就行了。但是 Docker 服务器启动之后，这样的操作肯定是没有了，就算可以借助 Portainer 的 UI，长久打算，最后还是要下定觉悟使用 SSH 来进行连接！</p><figure class="highlight bash"><figcaption><span>拉取容器</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull ubuntu<br></code></pre></td></tr></table></figure><p>一般都是在 Docker Desktop 操作的吧，然后手动在 images 点击启动，也许是不行的吧哈哈，果然还是要 docker run -it xxxxx 的吧，这样的话，就看看另一边 Docker 最基础命令的文章吧。如果没有方便的终端窗口的话，果然还是要手动 docker exec xxx /bin/bash 的吧，所以还不学习一下吗哈哈哈。</p><p>最后，终于进入了容器内部的 Terminal 的勇者一行们…</p><p>最后，面对 ubuntu 容器的 Terminal，终于可以开始了。</p><figure class="highlight bash"><figcaption><span>更新一下，安装vim</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">apt update<br>apt install vim -y<br></code></pre></td></tr></table></figure><p>安装好 vim 这个很方便的编辑器后，可以很方便换 apt 的源，加快在大陆地区的下载更新速度。<br>vim 的基础语法请搜索引擎一下啦，这里就不写了呢，哼~。</p><figure class="highlight bash"><figcaption><span>vim替换源</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">vim /etc/apt/sources.list<br>:%s/archive.ubuntu.com/mirrors.aliyun.com <span class="hljs-comment">#默认写了阿里云的源啦，自行搜索选择啦</span><br>apt update <span class="hljs-comment"># 完毕退出 vim 之后，再更新一下仓库索引吧</span><br></code></pre></td></tr></table></figure><p>然后要安装 SSH 的服务端呢，ubuntu 基础的 image 中没带哦</p><figure class="highlight bash"><figcaption><span>安排ssh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">apt install openssh-server -y<br>选择 6.Asia; 70.Shanghai 时区<br>passwd <span class="hljs-comment"># 创建一个密码啦</span><br>vim /etc/ssh/sshd_config <span class="hljs-comment"># 编辑一下配置，开启密码登录，在 sshd_config 加入</span><br>PermitRootLogin <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure><p>完毕啦，但是为了安全起见，后面要改用证书登录的形式啦~<br>最后，重启一下 sshd 的服务，开始使用吧，因为是容器 ubuntu 的缘故，貌似用不了 systemd 呢~</p><figure class="highlight bash"><figcaption><span>重启ssh服务</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">/etc/init.d/ssh restart<br></code></pre></td></tr></table></figure><p>最后，给懒人推荐一个已经帮你配好的 ubuntu 镜像地址，就是内容有点旧。</p><a href="https://hub.docker.com/[object%20Object]ubuntu-sshd/" title="" target="">rastasheep&#x2F;ubuntu-sshd</a>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git 一些补充知识</title>
    <link href="/2022/02/19/git/"/>
    <url>/2022/02/19/git/</url>
    
    <content type="html"><![CDATA[<h1 id="Git-设置-Proxy"><a href="#Git-设置-Proxy" class="headerlink" title="Git 设置 Proxy"></a>Git 设置 Proxy</h1><p>出于一些众所周知的原因，在大陆使用 Github 相关服务，需要配合一些工具。</p><figure class="highlight bash"><figcaption><span>Set_Http_Proxy</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git config --global http.proxy http://ip:port<br></code></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>Unset_Http_Proxy</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git config --global --<span class="hljs-built_in">unset</span> http.proxy<br></code></pre></td></tr></table></figure><h1 id="Git-设置用户名和邮箱"><a href="#Git-设置用户名和邮箱" class="headerlink" title="Git 设置用户名和邮箱"></a>Git 设置用户名和邮箱</h1><figure class="highlight bash"><figcaption><span>全局</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git config --global user.name <span class="hljs-string">&quot;Sawamura Mouichirou&quot;</span><br>git config --global user.email <span class="hljs-string">&quot;myemailaddress&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>用户级</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git config user.name <span class="hljs-string">&quot;Sawamura Mouichirou&quot;</span><br>git config user.email <span class="hljs-string">&quot;myemailaddress&quot;</span><br></code></pre></td></tr></table></figure><p>注意：用户级配置会比全局更优先</p><h1 id="Git-GPG-keys"><a href="#Git-GPG-keys" class="headerlink" title="Git GPG keys"></a>Git GPG keys</h1>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
